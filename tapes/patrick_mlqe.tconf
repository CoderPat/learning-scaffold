global {
    ducttape_output="/projects/tir4/users/pfernand/workflows-outputs/metaexpl-experiments/mlqe-v1"
    ducttape_experimental_submitters=true
    ducttape_experimental_imports=true
    repo="/home/pfernand/repos/meta-expl"

    task="mlqe"
    num_examples=""

    # models and explainers parameters
    teacher_arch=mbert
    student_arch=embedding

    teacher_explainer=(
        TeacherExplainer:
            attention="attention_explainer"
            hidden_qk="hidden_qk_explainer"
            attention_query="attention_query_explainer"
    )
    student_explainer="attention_explainer"

    normalizer_fn=(NormalizerFn: softmax entmax)

    # optimization paramaters
    num_epochs=""
    batch_size=16
    lr=1e-5
    kld_coeff=(
        KLDCoeff: 
            0=0
            1=1
    )
    patience=(
        NumExamples:
            500=40
            1000=30
            2000=20
    )

    # (meta) optimization parameters
    metalearn=(
        MetaLearn:
            false=false
            true=true
    )
    meta_lr=(MetaLR: 1e-2 1e-3 5e-4 1e-4)
    meta_interval=(MetaInterval: 1 100)
    meta_explicit=(MetaExplicit: false true)

    seed=(Seed: 0 1 2) # 3 4)

    submitter=slurm
}

plan TrainTeacher {
    reach TrainTeacher
}

plan TrainStudent {
    reach AverageResults via (KLDCoeff: 0 1) * (TeacherExplainer: *)
}

plan MetaTrain {
    reach AverageResults via (KLDCoeff: 1) * (MetaLearn: true) * (TeacherExplainer: *) * (MetaLR: 5e-4) * (MetaInterval: *)
}

#plan EntmaxExperiments {
#    reach AverageResults via (NumExamples: 2000) * (KLDCoeff: 0 1) * (TeacherExplainer: attention_query) * (NormalizerFn: entmax)
#    reach AverageResults via (NumExamples: 2000) * (KLDCoeff: 1) * (MetaLearn: true) * (TeacherExplainer: attention_query) * (MetaLR: 5e-4) * (MetaInterval: *) * (NormalizerFn: entmax)
#}

