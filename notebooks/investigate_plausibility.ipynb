{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0f173f6e",
   "metadata": {},
   "source": [
    "set cuda id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e5442597",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
      "env: CUDA_VISIBLE_DEVICES=6\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
    "%env CUDA_VISIBLE_DEVICES=6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0343ff12",
   "metadata": {},
   "source": [
    "Install dependencies for computing metrics and plots:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7b7502e9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#!pip3 install numpy scipy pandas seaborn matplotlib sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6e1ab61",
   "metadata": {},
   "source": [
    "## Basic imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "111e491d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import flax\n",
    "from entmax_jax import sparsemax\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from IPython.display import display, HTML\n",
    "from functools import partial\n",
    "import json\n",
    "from entmax_jax.activations import sparsemax, entmax15\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "\n",
    "from meta_expl.explainers import load_explainer\n",
    "from meta_expl.models import load_model\n",
    "from meta_expl.data.mlqe import dataloader\n",
    "\n",
    "from evaluate_explanations import evaluate_word_level, evaluate_sentence_level, aggregate_pieces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "696c7a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data utils\n",
    "def unroll(list_of_lists):\n",
    "    return [e for ell in list_of_lists for e in ell]\n",
    "\n",
    "def read_data(lp, split='dev'):\n",
    "    def tags_to_ints(line):\n",
    "        return list(map(int, line.strip().replace('OK', '0').replace('BAD', '1').split()))\n",
    "    data = {\n",
    "        'original': [line.strip() for line in open('data/mlqepe/{}/{}.src'.format(lp, split), 'r')],\n",
    "        'translation': [line.strip() for line in open('data/mlqepe/{}/{}.mt'.format(lp, split), 'r')],\n",
    "        'z_mean': [float(line.strip()) for line in open('data/mlqepe/{}/{}.da'.format(lp, split), 'r')],\n",
    "        'src_tags': [tags_to_ints(line) for line in open('data/mlqepe/{}/{}.src-tags'.format(lp, split), 'r')],\n",
    "        'mt_tags': [tags_to_ints(line) for line in open('data/mlqepe/{}/{}.tgt-tags'.format(lp, split), 'r')]\n",
    "    }\n",
    "    data['da'] = data['z_mean']\n",
    "    data = [dict(zip(data.keys(), v)) for v in list(zip(*data.values()))]\n",
    "    return data\n",
    "\n",
    "def read_data_all(lps, split='dev'):\n",
    "    data = {\n",
    "        'original': [],\n",
    "        'translation': [],\n",
    "        'z_mean': [],\n",
    "        'src_tags': [],\n",
    "        'mt_tags': [],\n",
    "    }\n",
    "    data['da'] = data['z_mean']\n",
    "    for lp in lps:\n",
    "        ell = read_data(lp, split)\n",
    "        for key in data.keys():\n",
    "            data[key].extend([d[key] for d in ell])\n",
    "    data = [dict(zip(data.keys(), v)) for v in list(zip(*data.values()))]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0051472",
   "metadata": {},
   "source": [
    "## Define args and load stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e77dafcf",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# arguments\n",
    "arch = 'xlm-roberta-base'\n",
    "arch_mtl = 'xlm-r'\n",
    "setup = 'no_teacher'  # \"no_teacher\", \"static_teacher\", \"learnable_teacher\"\n",
    "# langpairs = [\"en-de\", \"en-zh\", \"et-en\", \"ne-en\", \"ro-en\", \"ru-en\"]\n",
    "lp = 'ro-en'\n",
    "max_len = 256\n",
    "batch_size = 16\n",
    "seed = 1\n",
    "sep_token = \"</s>\" if 'xlm' in arch else \"[SEP]\"\n",
    "dataloader = partial(dataloader, sep_token=sep_token)\n",
    "num_classes = 1\n",
    "task_type = \"regression\"\n",
    "teacher_dir = 'data/mlqe-xlmr-models/teacher_dir'\n",
    "explainer_dir = 'data/mlqe-xlmr-models/teacher_expl_dir'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a323ee16",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:Unable to initialize backend 'tpu_driver': NOT_FOUND: Unable to find driver in registry given worker: \n",
      "INFO:absl:Unable to initialize backend 'tpu': INVALID_ARGUMENT: TpuPlatform is not available.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(16, 256)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create dummy inputs for model instantiation\n",
    "input_ids = jnp.ones((batch_size, max_len), jnp.int32)\n",
    "dummy_inputs = {\n",
    "    \"input_ids\": input_ids,\n",
    "    \"attention_mask\": jnp.ones_like(input_ids),\n",
    "    \"token_type_ids\": jnp.arange(jnp.atleast_2d(input_ids).shape[-1]),\n",
    "    \"position_ids\": jnp.ones_like(input_ids),\n",
    "}\n",
    "dummy_inputs['input_ids'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1f4f9ad",
   "metadata": {},
   "source": [
    "### load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1c07f5c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "train_data = read_data(lp, \"train\")\n",
    "valid_data = read_data(lp, \"dev\")\n",
    "test_data = read_data(lp, \"test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f90ea756",
   "metadata": {},
   "source": [
    "### load tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bbf471df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import XLMRobertaTokenizerFast\n",
    "tokenizer = XLMRobertaTokenizerFast.from_pretrained(arch)\n",
    "cls_id = tokenizer.cls_token_id\n",
    "sep_id = tokenizer.sep_token_id\n",
    "pad_id = tokenizer.pad_token_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7df6d85",
   "metadata": {},
   "source": [
    "### load model and explainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "478ee21f",
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher, teacher_params, dummy_state = load_model(teacher_dir, batch_size, max_len)\n",
    "teacher_explainer, teacher_explainer_params = load_explainer(explainer_dir, dummy_inputs, state=dummy_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fe63b22a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from meta_expl.utils import PRNGSequence\n",
    "# from meta_expl.explainers import create_explainer\n",
    "# keyseq = PRNGSequence(11)\n",
    "# teacher_explainer_params={\n",
    "#     'normalize_head_coeffs': 'sparsemax',\n",
    "#     'normalizer_fn': 'softmax',\n",
    "#     'aggregator_idx': 'mean',\n",
    "#     'aggregator_dim': 'row',\n",
    "#     'init_fn': 'uniform',\n",
    "#     'layer_idx': 9,  #9, None\n",
    "#     'head_idx': 5,  #5, None\n",
    "# }\n",
    "# explainer_type='attention_explainer'\n",
    "# teacher_explainer, teacher_explainer_params = create_explainer(next(keyseq), dummy_inputs, dummy_state, \n",
    "#                                      explainer_type, explainer_args=teacher_explainer_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2d09885",
   "metadata": {},
   "source": [
    "### look at the coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c2e0f46b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeviceArray([[0.05825656, 0.05605122, 0.06579615, 0.06052823, 0.05019351,\n",
       "              0.0858976 , 0.04817941, 0.05621345, 0.01868655, 0.02941416,\n",
       "              0.04372283, 0.05819663],\n",
       "             [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "              0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "              0.        , 0.        ],\n",
       "             [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "              0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "              0.        , 0.        ],\n",
       "             [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "              0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "              0.        , 0.        ],\n",
       "             [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "              0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "              0.0433885 , 0.        ],\n",
       "             [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "              0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "              0.        , 0.        ],\n",
       "             [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "              0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "              0.        , 0.        ],\n",
       "             [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "              0.        , 0.        , 0.        , 0.08041232, 0.09685925,\n",
       "              0.        , 0.        ],\n",
       "             [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "              0.0302523 , 0.        , 0.03107029, 0.        , 0.        ,\n",
       "              0.        , 0.        ],\n",
       "             [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "              0.04859592, 0.        , 0.        , 0.        , 0.        ,\n",
       "              0.        , 0.        ],\n",
       "             [0.        , 0.02883356, 0.        , 0.00945152, 0.        ,\n",
       "              0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "              0.        , 0.        ],\n",
       "             [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "              0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "              0.        , 0.        ]], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sparsemax(teacher_explainer_params['params']['head_coeffs']).reshape(12, 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8a706e2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 1\n",
      "1 2\n",
      "1 3\n",
      "1 4\n",
      "1 5\n",
      "1 6\n",
      "1 7\n",
      "1 8\n",
      "1 9\n",
      "1 10\n",
      "1 11\n",
      "1 12\n",
      "5 11\n",
      "8 9\n",
      "8 10\n",
      "9 6\n",
      "9 8\n",
      "10 6\n",
      "11 2\n",
      "11 4\n"
     ]
    }
   ],
   "source": [
    "hc = sparsemax(teacher_explainer_params['params']['head_coeffs']).reshape(12, 12)\n",
    "for a, b in zip(*hc.nonzero()):\n",
    "    print(a+1, b+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "18549d54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2, 0.0),\n",
       " (3, 0.0),\n",
       " (4, 0.0),\n",
       " (6, 0.0),\n",
       " (7, 0.0),\n",
       " (12, 0.0),\n",
       " (11, 0.003190424060449004),\n",
       " (5, 0.003615708090364933),\n",
       " (10, 0.004049660172313452),\n",
       " (9, 0.005110216327011585),\n",
       " (8, 0.014772631227970123),\n",
       " (1, 0.052594687789678574)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the layers with the highest coefficients\n",
    "layer_coeffs = sparsemax(teacher_explainer_params['params']['head_coeffs']).reshape(12, 12).mean(-1).tolist()\n",
    "sorted(list(zip(list(range(1, len(layer_coeffs)+1)), layer_coeffs)), key=lambda k: k[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0a705b0",
   "metadata": {},
   "source": [
    "## Get explanations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "22b7e6a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_explanations(data, strategy='mtl', layer_id=0, head_id=0):\n",
    "    all_tokens = []\n",
    "    all_masks = []\n",
    "    all_explanations = []\n",
    "    all_outputs = []\n",
    "    c = 1\n",
    "    for x, y in dataloader(data, tokenizer, batch_size=batch_size, max_len=max_len, shuffle=False):\n",
    "        print('{} of {}'.format(c, len(data) // batch_size + 1), end='\\r')\n",
    "        c += 1\n",
    "        \n",
    "        # get teacher output\n",
    "        # y_teacher, teacher_attn = jax.jit(lambda x: teacher.apply(teacher_params, **x, deterministic=True))(x)\n",
    "        y_teacher, teacher_attn = teacher.apply(teacher_params, **x, deterministic=True)\n",
    "        if task_type == \"classification\":\n",
    "            y_teacher = jnp.argmax(y_teacher, axis=-1)\n",
    "        \n",
    "        # use the explanation given to the student by the teacher explainer\n",
    "        if strategy == 'mtl':\n",
    "            # get explanation from the teacher explainer\n",
    "            teacher_expl, _ = teacher_explainer.apply(teacher_explainer_params, x, teacher_attn)\n",
    "        \n",
    "        # use the explanation from the best head at the best layer (according to the coefficients)\n",
    "        elif strategy == 'top_layer_head':\n",
    "            # batch x layers x heads x seqlen x seqlen\n",
    "            all_attentions = jnp.stack(teacher_attn['attentions']).transpose([1, 0, 2, 3, 4])\n",
    "            num_layers = all_attentions.shape[1] \n",
    "            num_heads = all_attentions.shape[2]\n",
    "\n",
    "            # get the attention from the teacher associated with the top head coeff\n",
    "            head_coeffs = sparsemax(teacher_explainer_params['params']['head_coeffs'])\n",
    "            top_joint_id = jnp.argmax(head_coeffs).item()\n",
    "            top_layer_id = top_joint_id // num_heads\n",
    "            top_head_id = top_joint_id % num_heads\n",
    "            attn = all_attentions[:, top_layer_id, top_head_id]\n",
    "            mask = x['attention_mask']\n",
    "            teacher_expl = (attn * mask[:, :, None]).sum(-2) / mask.sum(-1)[:, None]\n",
    "        \n",
    "        # average a specific layer\n",
    "        elif strategy == 'layer_average':\n",
    "            all_attentions = jnp.stack(teacher_attn['attentions']).transpose([1, 0, 2, 3, 4])\n",
    "            attn = all_attentions[:, layer_id].mean(1)\n",
    "            mask = x['attention_mask']\n",
    "            teacher_expl = (attn * mask[:, :, None]).sum(-2) / mask.sum(-1)[:, None]\n",
    "        \n",
    "        # use a specific head at a specific layer\n",
    "        elif strategy == 'layer_head':\n",
    "            all_attentions = jnp.stack(teacher_attn['attentions']).transpose([1, 0, 2, 3, 4])\n",
    "            attn = all_attentions[:, layer_id, head_id]\n",
    "            mask = x['attention_mask']\n",
    "            teacher_expl = (attn * mask[:, :, None]).sum(-2) / mask.sum(-1)[:, None]\n",
    "        \n",
    "        # return all nonzero attention explanations (not tested)\n",
    "        else:\n",
    "            # get all attentions from the teacher associated with nonzero head coeff\n",
    "            head_coeffs = head_coeffs.reshape(num_layers, num_heads)\n",
    "            nonzero_rows, nonzero_cols = head_coeffs.nonzero()\n",
    "            num_nonzero = len(nonzero_rows)\n",
    "            attn = jnp.stack([\n",
    "                all_attentions[:, r, c] for r, c in zip(nonzero_rows.tolist(), nonzero_cols.tolist())\n",
    "            ]).transpose([1, 0, 2, 3])  # batch, num_nonzero, seqlen, seqlen\n",
    "            mask = x['attention_mask']\n",
    "            teacher_expl = (attn * mask[..., None]).sum(-2) / mask.sum(-1)[..., None]\n",
    "\n",
    "        # convert everything to lists\n",
    "        batch_ids = x['input_ids'].tolist()\n",
    "        batch_tokens = [tokenizer.convert_ids_to_tokens(ids) for ids in batch_ids]\n",
    "        batch_masks = [[tk.startswith('▁') for tk in tokens] for tokens in batch_tokens]\n",
    "        batch_expls = teacher_expl.tolist()\n",
    "        \n",
    "        # filter out pad\n",
    "        batch_valid_len = x['attention_mask'].sum(-1).tolist()\n",
    "        for i in range(len(batch_valid_len)):\n",
    "            n = batch_valid_len[i]\n",
    "            batch_ids[i] = batch_ids[i][:n]\n",
    "            batch_tokens[i] = batch_tokens[i][:n]\n",
    "            batch_masks[i] = batch_masks[i][:n]\n",
    "            batch_expls[i] = batch_expls[i][:n]\n",
    "        \n",
    "        all_tokens.extend(batch_tokens)\n",
    "        all_masks.extend(batch_masks)\n",
    "        all_explanations.extend(batch_expls)\n",
    "        all_outputs.extend(y_teacher.tolist())\n",
    "\n",
    "    return all_tokens, all_masks, all_explanations, all_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ead4a0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "valid_tokens, valid_masks, valid_explanations, valid_outputs = get_explanations(\n",
    "    valid_data, strategy='mtl'\n",
    ")\n",
    "list(map(len, [valid_tokens, valid_masks, valid_explanations, valid_outputs]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2ab6508",
   "metadata": {},
   "source": [
    "### Aggregate scores for word pieces in SRC and MT independently"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "31a1ae7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from utils import aggregate_pieces\n",
    "\n",
    "def get_src_and_mt_explanations(all_tokens, all_fp_masks, all_explanations, reduction):\n",
    "    src_expls = []\n",
    "    mt_expls = []\n",
    "    src_pieces = []\n",
    "    mt_pieces = []\n",
    "    for tokens, expl, fp_mask in zip(all_tokens, all_explanations, all_fp_masks):\n",
    "        # split data into src and mt (assuming \"<s> src </s> mt </s>\" format without CLS for mt) \n",
    "        src_len = tokens.index(tokenizer.sep_token) + 1\n",
    "        src_tokens, mt_tokens = tokens[:src_len], tokens[src_len:]\n",
    "        src_expl, mt_expl = expl[:src_len], expl[src_len:]\n",
    "        src_fp_mask, mt_fp_mask = fp_mask[:src_len], fp_mask[src_len:]\n",
    "        \n",
    "        # aggregate word pieces scores (use my old good torch function)\n",
    "        agg_src_expl = aggregate_pieces(torch.tensor(src_expl), torch.tensor(src_fp_mask), reduction)\n",
    "        agg_mt_expl = aggregate_pieces(torch.tensor(mt_expl), torch.tensor(mt_fp_mask), reduction)\n",
    "        \n",
    "        # remove <s> and </s> from src\n",
    "        agg_src_expl = agg_src_expl.tolist()[1:-1]\n",
    "        # remove </s> from mt\n",
    "        agg_mt_expl = agg_mt_expl.tolist()[:-1]\n",
    "        \n",
    "        src_pieces.append(src_tokens)\n",
    "        mt_pieces.append(mt_tokens)\n",
    "        src_expls.append(agg_src_expl)\n",
    "        mt_expls.append(agg_mt_expl)\n",
    "    return src_expls, mt_expls, src_pieces, mt_pieces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea29155a",
   "metadata": {},
   "outputs": [],
   "source": [
    "reduction = 'sum'  # first, sum, mean, max\n",
    "src_expls, mt_expls, src_pieces, mt_pieces = get_src_and_mt_explanations(\n",
    "    valid_tokens, valid_masks, valid_explanations, reduction=reduction\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99616e11",
   "metadata": {},
   "source": [
    "## Evaluating explanations by comparing explanations with word-level QE tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "874d3715",
   "metadata": {},
   "outputs": [],
   "source": [
    "gold_src_tokens = [inp['original'].split() for inp in valid_data]\n",
    "gold_mt_tokens = [inp['translation'].split() for inp in valid_data]\n",
    "gold_expls_src = [inp['src_tags'] for inp in valid_data]\n",
    "gold_expls_mt = [inp['mt_tags'] for inp in valid_data]\n",
    "gold_scores = [inp['z_mean'] for inp in valid_data]\n",
    "\n",
    "pred_expls_src = src_expls\n",
    "pred_expls_mt = mt_expls\n",
    "pred_scores = unroll(valid_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0a6069c",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = evaluate_sentence_level(gold_scores, pred_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fad2aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = evaluate_word_level(gold_expls_src, pred_expls_src)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95bfff3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = evaluate_word_level(gold_expls_mt, pred_expls_mt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ae28f40",
   "metadata": {},
   "source": [
    "## Evaluate all LPs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4ec137a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_diff_seq_len(gold, pred):\n",
    "    new_pred, new_gold = [], []\n",
    "    t = 0\n",
    "    for p, g in zip(pred, gold):\n",
    "        if len(p) == len(g):\n",
    "            new_pred.append(p)\n",
    "            new_gold.append(g)\n",
    "        else:\n",
    "            t += 1\n",
    "    print('filtered:', t)\n",
    "    return new_gold, new_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8b2dcda8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63 of 63\n",
      "ru-en\n",
      "----------\n",
      "filtered: 1\n",
      "filtered: 1\n",
      "Pearson: 0.6226\n",
      "Spearman: 0.5725\n",
      "MAE: 0.5733\n",
      "RMSE: 0.7866\n",
      "AUC score: 0.5845\n",
      "AP score: 0.5396\n",
      "Recall at top-K: 0.3974\n",
      "AUC score: 0.5769\n",
      "AP score: 0.5154\n",
      "Recall at top-K: 0.3845\n"
     ]
    }
   ],
   "source": [
    "langpairs = [\"en-de\", \"en-zh\", \"et-en\", \"ne-en\", \"ro-en\", \"ru-en\", \"all\"]\n",
    "split = \"test\"\n",
    "for lp in langpairs:\n",
    "    if lp == \"all\":\n",
    "        data = read_data_all(langpairs[:-1], split)\n",
    "    else:\n",
    "        data = read_data(lp, split)\n",
    "    valid_tokens, valid_masks, valid_explanations, valid_outputs = get_explanations(data, strategy='mtl')\n",
    "    print('')\n",
    "    print(lp)\n",
    "    print('----------')\n",
    "    src_expls, mt_expls, src_pieces, mt_pieces = get_src_and_mt_explanations(\n",
    "        valid_tokens, valid_masks, valid_explanations, reduction='sum'\n",
    "    )\n",
    "    gold_src_tokens = [inp['original'].split() for inp in data]\n",
    "    gold_mt_tokens = [inp['translation'].split() for inp in data]\n",
    "    gold_expls_src = [inp['src_tags'] for inp in data]\n",
    "    gold_expls_mt = [inp['mt_tags'] for inp in data]\n",
    "    gold_scores = [inp['z_mean'] for inp in data]\n",
    "    pred_expls_src = src_expls\n",
    "    pred_expls_mt = mt_expls\n",
    "    pred_scores = unroll(valid_outputs)\n",
    "    gold_expls_src, pred_expls_src = filter_diff_seq_len(gold_expls_src, pred_expls_src)\n",
    "    gold_expls_mt, pred_expls_mt = filter_diff_seq_len(gold_expls_mt, pred_expls_mt)\n",
    "    evaluate_sentence_level(gold_scores, pred_scores)\n",
    "    evaluate_word_level(gold_expls_src, pred_expls_src)\n",
    "    evaluate_word_level(gold_expls_mt, pred_expls_mt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3a74f48e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "375 of 376\n",
      "all | LAYER: 9 | HEAD: 5\n",
      "---\n",
      "filtered: 1\n",
      "filtered: 1\n",
      "AUC score: 0.6674\n",
      "AP score: 0.5972\n",
      "Recall at top-K: 0.4827\n",
      "AUC score: 0.6401\n",
      "AP score: 0.6007\n",
      "Recall at top-K: 0.4911\n"
     ]
    }
   ],
   "source": [
    "layer_id = 9\n",
    "head_id = 5\n",
    "langpairs = [\"en-de\", \"en-zh\", \"et-en\", \"ne-en\", \"ro-en\", \"ru-en\", \"all\"]\n",
    "split = \"test\"  # train, dev, test\n",
    "for lp in langpairs:\n",
    "    if lp == \"all\":\n",
    "        data = read_data_all(langpairs[:-1], split)\n",
    "    else:\n",
    "        data = read_data(lp, split)\n",
    "    valid_tokens, valid_masks, valid_explanations, valid_outputs = get_explanations(\n",
    "        data, strategy='layer_head', layer_id=layer_id, head_id=head_id\n",
    "    )\n",
    "    src_expls, mt_expls, src_pieces, mt_pieces = get_src_and_mt_explanations(\n",
    "        valid_tokens, valid_masks, valid_explanations, reduction='sum'\n",
    "    )\n",
    "    print('')\n",
    "    print('{} | LAYER: {} | HEAD: {}'.format(lp, layer_id, head_id))\n",
    "    print('---')\n",
    "    gold_expls_src = [inp['src_tags'] for inp in data]\n",
    "    gold_expls_mt = [inp['mt_tags'] for inp in data]\n",
    "    gold_expls_src, src_expls = filter_diff_seq_len(gold_expls_src, src_expls)\n",
    "    gold_expls_mt, mt_expls = filter_diff_seq_len(gold_expls_mt, mt_expls)\n",
    "    _ = evaluate_word_level(gold_expls_src, src_expls)\n",
    "    _ = evaluate_word_level(gold_expls_mt, mt_expls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b632e2c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63 of 63\n",
      "en-de | LAYER: 9 | HEAD: 5\n",
      "---\n",
      "filtered: 0\n",
      "filtered: 0\n",
      "AUC score: 0.6711\n",
      "AP score: 0.4827\n",
      "Recall at top-K: 0.3530\n",
      "AUC score: 0.6569\n",
      "AP score: 0.5044\n",
      "Recall at top-K: 0.3771\n",
      "63 of 63\n",
      "en-zh | LAYER: 9 | HEAD: 5\n",
      "---\n",
      "filtered: 0\n",
      "filtered: 0\n",
      "AUC score: 0.5652\n",
      "AP score: 0.4812\n",
      "Recall at top-K: 0.3638\n",
      "AUC score: 0.5422\n",
      "AP score: 0.4911\n",
      "Recall at top-K: 0.3787\n",
      "63 of 63\n",
      "et-en | LAYER: 9 | HEAD: 5\n",
      "---\n",
      "filtered: 0\n",
      "filtered: 0\n",
      "AUC score: 0.6835\n",
      "AP score: 0.5592\n",
      "Recall at top-K: 0.4343\n",
      "AUC score: 0.6724\n",
      "AP score: 0.5500\n",
      "Recall at top-K: 0.4374\n",
      "63 of 63\n",
      "ne-en | LAYER: 9 | HEAD: 5\n",
      "---\n",
      "filtered: 0\n",
      "filtered: 0\n",
      "AUC score: 0.6967\n",
      "AP score: 0.7661\n",
      "Recall at top-K: 0.6845\n",
      "AUC score: 0.6348\n",
      "AP score: 0.7920\n",
      "Recall at top-K: 0.7121\n",
      "63 of 63\n",
      "ro-en | LAYER: 9 | HEAD: 5\n",
      "---\n",
      "filtered: 0\n",
      "filtered: 0\n",
      "AUC score: 0.7237\n",
      "AP score: 0.6055\n",
      "Recall at top-K: 0.4929\n",
      "AUC score: 0.7159\n",
      "AP score: 0.5837\n",
      "Recall at top-K: 0.4584\n",
      "63 of 63\n",
      "ru-en | LAYER: 9 | HEAD: 5\n",
      "---\n",
      "filtered: 0\n",
      "filtered: 1\n",
      "AUC score: 0.6547\n",
      "AP score: 0.5742\n",
      "Recall at top-K: 0.4328\n",
      "AUC score: 0.5767\n",
      "AP score: 0.5321\n",
      "Recall at top-K: 0.4084\n",
      "375 of 376\n",
      "all | LAYER: 9 | HEAD: 5\n",
      "---\n",
      "filtered: 0\n",
      "filtered: 1\n",
      "AUC score: 0.6681\n",
      "AP score: 0.5903\n",
      "Recall at top-K: 0.4759\n",
      "AUC score: 0.6367\n",
      "AP score: 0.5911\n",
      "Recall at top-K: 0.4806\n"
     ]
    }
   ],
   "source": [
    "layer_id = 9\n",
    "head_id = 5\n",
    "langpairs = [\"en-de\", \"en-zh\", \"et-en\", \"ne-en\", \"ro-en\", \"ru-en\", \"all\"]\n",
    "split = \"dev\"  # train, dev, test\n",
    "for lp in langpairs:\n",
    "    if lp == \"all\":\n",
    "        data = read_data_all(langpairs[:-1], split)\n",
    "    else:\n",
    "        data = read_data(lp, split)\n",
    "    valid_tokens, valid_masks, valid_explanations, valid_outputs = get_explanations(\n",
    "        data, strategy='layer_head', layer_id=layer_id, head_id=head_id\n",
    "    )\n",
    "    src_expls, mt_expls, src_pieces, mt_pieces = get_src_and_mt_explanations(\n",
    "        valid_tokens, valid_masks, valid_explanations, reduction='sum'\n",
    "    )\n",
    "    print('')\n",
    "    print('{} | LAYER: {} | HEAD: {}'.format(lp, layer_id, head_id))\n",
    "    print('---')\n",
    "    gold_expls_src = [inp['src_tags'] for inp in data]\n",
    "    gold_expls_mt = [inp['mt_tags'] for inp in data]\n",
    "    gold_expls_src, src_expls = filter_diff_seq_len(gold_expls_src, src_expls)\n",
    "    gold_expls_mt, mt_expls = filter_diff_seq_len(gold_expls_mt, mt_expls)\n",
    "    _ = evaluate_word_level(gold_expls_src, src_expls)\n",
    "    _ = evaluate_word_level(gold_expls_mt, mt_expls)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae36857a",
   "metadata": {},
   "source": [
    "## Plotting the distribution of predictions and AUC scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f1cf53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define options for seaborn\n",
    "custom_params = {\n",
    "    'axes.spines.right': False,\n",
    "    'axes.spines.top': False,\n",
    "    'grid.color': '.85',\n",
    "    'grid.linestyle': ':'\n",
    "}\n",
    "_ = sns.set_theme(style='whitegrid', rc=custom_params),\n",
    "\n",
    "def plot_da_vs_expl_metric(metric_fn, das, e_golds, e_preds):\n",
    "    x = []\n",
    "    y = []\n",
    "    for da, gold, pred in zip(das, e_golds, e_preds):\n",
    "        if sum(gold) == 0 or sum(gold) == len(gold):\n",
    "            continue\n",
    "        y.append(metric_fn(gold, pred))\n",
    "        x.append(da)\n",
    "    x = np.array(x)\n",
    "    y = np.array(y)\n",
    "    fig, axs = plt.subplots(1, 3, figsize=(16, 4))\n",
    "    sns.histplot(x=x, y=y, ax=axs[0])\n",
    "    axs[0].set_xlabel('da')\n",
    "    axs[0].set_ylabel(str(metric_fn).split()[1])\n",
    "    sns.histplot(x, bins=20, ax=axs[1])\n",
    "    axs[1].set_xlabel('da')\n",
    "    sns.histplot(y, bins=20, ax=axs[2])\n",
    "    axs[2].set_xlabel(str(metric_fn).split()[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a0b03c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot predicted DA vs AUC for src and mt\n",
    "plot_da_vs_expl_metric(roc_auc_score, pred_scores, gold_expls_src, pred_expls_src)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e42f92e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_da_vs_expl_metric(roc_auc_score, pred_scores, gold_expls_mt, pred_expls_mt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e659af49",
   "metadata": {},
   "source": [
    "## Check results for all layers (slooow -> very inefficient)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "347adcb6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for layer_id in range(12):\n",
    "    valid_tokens, valid_masks, valid_explanations, valid_outputs = get_explanations(\n",
    "        valid_data, strategy='layer_average', layer_id=layer_id\n",
    "    )\n",
    "    src_expls, mt_expls, src_pieces, mt_pieces = get_src_and_mt_explanations(\n",
    "        valid_tokens, valid_masks, valid_explanations, reduction='sum'\n",
    "    )\n",
    "    print('LAYER: {}'.format(layer_id))\n",
    "    _ = evaluate_word_level(gold_expls_src, src_expls)\n",
    "    _ = evaluate_word_level(gold_expls_mt, mt_expls)\n",
    "    print('---')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23aa5101",
   "metadata": {},
   "source": [
    "## Check results for all heads in all layers ((very slow)^2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37f9e36b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for layer_id in range(12):\n",
    "    for head_id in range(12):\n",
    "        valid_tokens, valid_masks, valid_explanations, valid_outputs = get_explanations(\n",
    "            valid_data, strategy='layer_head', layer_id=layer_id, head_id=head_id\n",
    "        )\n",
    "        src_expls, mt_expls, src_pieces, mt_pieces = get_src_and_mt_explanations(\n",
    "            valid_tokens, valid_masks, valid_explanations, reduction='sum'\n",
    "        )\n",
    "        print('LAYER: {} | HEAD: {}'.format(layer_id, head_id))\n",
    "        _ = evaluate_word_level(gold_expls_src, src_expls)\n",
    "        _ = evaluate_word_level(gold_expls_mt, mt_expls)\n",
    "        print('---')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
