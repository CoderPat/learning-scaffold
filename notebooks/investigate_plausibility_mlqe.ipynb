{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0f173f6e",
   "metadata": {},
   "source": [
    "set cuda id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5442597",
   "metadata": {},
   "outputs": [],
   "source": [
    "%env CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
    "%env CUDA_VISIBLE_DEVICES=4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0343ff12",
   "metadata": {},
   "source": [
    "Install dependencies for computing metrics and plots:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b7502e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip3 install numpy scipy pandas seaborn matplotlib sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6e1ab61",
   "metadata": {},
   "source": [
    "## Basic imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "111e491d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import flax\n",
    "from entmax_jax import sparsemax\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from IPython.display import display, HTML\n",
    "from functools import partial\n",
    "import json\n",
    "from entmax_jax.activations import sparsemax, entmax15\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "\n",
    "from meta_expl.explainers import load_explainer\n",
    "from meta_expl.models import load_model\n",
    "from meta_expl.data.mlqe import dataloader\n",
    "\n",
    "from evaluate_explanations import evaluate_word_level, evaluate_sentence_level, aggregate_pieces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "696c7a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data utils\n",
    "def unroll(list_of_lists):\n",
    "    return [e for ell in list_of_lists for e in ell]\n",
    "\n",
    "def read_data(lp, split='dev'):\n",
    "    def tags_to_ints(line):\n",
    "        return list(map(int, line.strip().replace('OK', '0').replace('BAD', '1').split()))\n",
    "    data = {\n",
    "        'original': [line.strip() for line in open('data/mlqepe/{}/{}.src'.format(lp, split), 'r')],\n",
    "        'translation': [line.strip() for line in open('data/mlqepe/{}/{}.mt'.format(lp, split), 'r')],\n",
    "        'z_mean': [float(line.strip()) for line in open('data/mlqepe/{}/{}.da'.format(lp, split), 'r')],\n",
    "        'src_tags': [tags_to_ints(line) for line in open('data/mlqepe/{}/{}.src-tags'.format(lp, split), 'r')],\n",
    "        'mt_tags': [tags_to_ints(line) for line in open('data/mlqepe/{}/{}.tgt-tags'.format(lp, split), 'r')]\n",
    "    }\n",
    "    data['da'] = data['z_mean']\n",
    "    data = [dict(zip(data.keys(), v)) for v in list(zip(*data.values()))]\n",
    "    return data\n",
    "\n",
    "def read_data_all(lps, split='dev'):\n",
    "    data = {\n",
    "        'original': [],\n",
    "        'translation': [],\n",
    "        'z_mean': [],\n",
    "        'src_tags': [],\n",
    "        'mt_tags': [],\n",
    "    }\n",
    "    data['da'] = data['z_mean']\n",
    "    for lp in lps:\n",
    "        ell = read_data(lp, split)\n",
    "        for key in data.keys():\n",
    "            data[key].extend([d[key] for d in ell])\n",
    "    data = [dict(zip(data.keys(), v)) for v in list(zip(*data.values()))]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0051472",
   "metadata": {},
   "source": [
    "## Define args and load stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e77dafcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# arguments\n",
    "arch = 'xlm-roberta-base'\n",
    "arch_mtl = 'xlm-r'\n",
    "setup = 'no_teacher'  # \"no_teacher\", \"static_teacher\", \"learnable_teacher\"\n",
    "# langpairs = [\"en-de\", \"en-zh\", \"et-en\", \"ne-en\", \"ro-en\", \"ru-en\"]\n",
    "lp = 'ro-en'\n",
    "max_len = 256\n",
    "batch_size = 16\n",
    "seed = 1\n",
    "sep_token = \"</s>\" if 'xlm' in arch else \"[SEP]\"\n",
    "dataloader = partial(dataloader, sep_token=sep_token)\n",
    "num_classes = 1\n",
    "task_type = \"regression\"\n",
    "teacher_dir = 'data/mlqe-xlmr-models/teacher_dir'\n",
    "explainer_dir = 'data/mlqe-xlmr-models/teacher_expl_dir'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a323ee16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dummy inputs for model instantiation\n",
    "input_ids = jnp.ones((batch_size, max_len), jnp.int32)\n",
    "dummy_inputs = {\n",
    "    \"input_ids\": input_ids,\n",
    "    \"attention_mask\": jnp.ones_like(input_ids),\n",
    "    \"token_type_ids\": jnp.arange(jnp.atleast_2d(input_ids).shape[-1]),\n",
    "    \"position_ids\": jnp.ones_like(input_ids),\n",
    "}\n",
    "dummy_inputs['input_ids'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1f4f9ad",
   "metadata": {},
   "source": [
    "### load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c07f5c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "train_data = read_data(lp, \"train\")\n",
    "valid_data = read_data(lp, \"dev\")\n",
    "test_data = read_data(lp, \"test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f90ea756",
   "metadata": {},
   "source": [
    "### load tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbf471df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import XLMRobertaTokenizerFast\n",
    "tokenizer = XLMRobertaTokenizerFast.from_pretrained(arch)\n",
    "cls_id = tokenizer.cls_token_id\n",
    "sep_id = tokenizer.sep_token_id\n",
    "pad_id = tokenizer.pad_token_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7df6d85",
   "metadata": {},
   "source": [
    "### load model and explainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "478ee21f",
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher, teacher_params, dummy_state = load_model(teacher_dir, dummy_inputs, batch_size, max_len)\n",
    "teacher_explainer, teacher_explainer_params = load_explainer(explainer_dir, dummy_inputs, state=dummy_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f482d52e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from meta_expl.utils import PRNGSequence\n",
    "from meta_expl.explainers import create_explainer\n",
    "keyseq = PRNGSequence(11)\n",
    "teacher_explainer_params_non_trained={\n",
    "    'normalize_head_coeffs': 'sparsemax',\n",
    "    'normalizer_fn': 'softmax',\n",
    "    'aggregator_idx': 'mean',\n",
    "    'aggregator_dim': 'row',\n",
    "    'init_fn': 'uniform',\n",
    "    'layer_idx': None,\n",
    "    'head_idx': None\n",
    "}\n",
    "teacher_explainer_non_trained, teacher_explainer_params_non_trained = create_explainer(\n",
    "    key=next(keyseq),\n",
    "    inputs=dummy_inputs,\n",
    "    state=dummy_state,\n",
    "    explainer_type='attention_explainer',\n",
    "    explainer_args=teacher_explainer_params_non_trained,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe63b22a",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_head_teacher_explainer_params={\n",
    "    'normalize_head_coeffs': 'sparsemax',\n",
    "    'normalizer_fn': 'softmax',\n",
    "    'aggregator_idx': 'mean',\n",
    "    'aggregator_dim': 'row',\n",
    "    'init_fn': 'uniform',\n",
    "    'layer_idx': 9,  #9, None\n",
    "    'head_idx': 5,  #5, None\n",
    "}\n",
    "best_head_teacher_explainer, best_head_teacher_explainer_params = create_explainer(\n",
    "    key=next(keyseq), \n",
    "    inputs=dummy_inputs, \n",
    "    state=dummy_state, \n",
    "    explainer_type='attention_explainer', \n",
    "    explainer_args=best_head_teacher_explainer_params\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f07e2ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_layer_teacher_explainer_params={\n",
    "    'normalize_head_coeffs': 'sparsemax',\n",
    "    'normalizer_fn': 'softmax',\n",
    "    'aggregator_idx': 'mean',\n",
    "    'aggregator_dim': 'row',\n",
    "    'init_fn': 'uniform',\n",
    "    'layer_idx': 10,  #9, None\n",
    "    'head_idx': None,  #5, None\n",
    "}\n",
    "best_layer_teacher_explainer, best_layer_teacher_explainer_params = create_explainer(\n",
    "    key=next(keyseq), \n",
    "    inputs=dummy_inputs, \n",
    "    state=dummy_state, \n",
    "    explainer_type='attention_explainer', \n",
    "    explainer_args=best_layer_teacher_explainer_params\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7ac6a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_gradient_teacher_explainer, input_gradient_teacher_explainer_params = create_explainer(\n",
    "    key=next(keyseq), \n",
    "    inputs=dummy_inputs, \n",
    "    state=dummy_state, \n",
    "    explainer_type='gradient_input_explainer', \n",
    "    model_extras={\n",
    "        \"grad_fn\": teacher.apply(\n",
    "            teacher_params, dummy_inputs, method=teacher.embeddings_grad_fn\n",
    "        )\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbbf34ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "int_gradient_teacher_explainer, int_gradient_teacher_explainer_params = create_explainer(\n",
    "    key=next(keyseq), \n",
    "    inputs=dummy_inputs, \n",
    "    state=dummy_state, \n",
    "    explainer_type='integrated_gradients_explainer', \n",
    "    model_extras={\n",
    "        \"grad_fn\": teacher.apply(\n",
    "            teacher_params, dummy_inputs, method=teacher.embeddings_grad_fn\n",
    "        )\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2d09885",
   "metadata": {},
   "source": [
    "### look at the coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e0f46b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sparsemax(teacher_explainer_params['params']['head_coeffs']).reshape(12, 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a706e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "hc = sparsemax(teacher_explainer_params['params']['head_coeffs']).reshape(12, 12)\n",
    "for a, b in zip(*hc.nonzero()):\n",
    "    print(a+1, b+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18549d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the layers with the highest coefficients\n",
    "layer_coeffs = sparsemax(teacher_explainer_params['params']['head_coeffs']).reshape(12, 12).mean(-1).tolist()\n",
    "sorted(list(zip(list(range(1, len(layer_coeffs)+1)), layer_coeffs)), key=lambda k: k[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0a705b0",
   "metadata": {},
   "source": [
    "## Get explanations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33bd87c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_expls(data, t, t_p, t_e, t_e_p, s=None, s_p=None, s_e=None, s_e_p=None, is_grad_based=False):\n",
    "    all_tokens = []\n",
    "    all_masks = []\n",
    "    all_explanations = []\n",
    "    all_outputs = []\n",
    "    for i, (x, y) in enumerate(dataloader(data, tokenizer, batch_size=batch_size, max_len=max_len, shuffle=False)):\n",
    "        print('{} of {}'.format(i+1, len(data) // batch_size + 1), end='\\r')\n",
    "    \n",
    "        y_teacher, teacher_attn = t.apply(t_p, **x, deterministic=True)\n",
    "        y_teacher = jnp.argmax(y_teacher, axis=-1) if task_type == \"classification\" else y_teacher\n",
    "        \n",
    "        if is_grad_based:\n",
    "            teacher_extras = {\n",
    "                \"grad_fn\": t.apply(t_p, x, method=t.embeddings_grad_fn)\n",
    "            }\n",
    "            teacher_expl, _ = t_e.apply(t_e_p, x, teacher_attn, **teacher_extras)\n",
    "        else:\n",
    "            teacher_expl, _ = t_e.apply(t_e_p, x, teacher_attn)\n",
    "        # teacher_rep = teacher_attn['hidden_states'][0][0]\n",
    "        # teacher_attn = np.asarray(jnp.stack(teacher_attn['attentions']).transpose([1, 0, 2, 3, 4]))\n",
    "        \n",
    "        if s is not None:\n",
    "            y_student, student_attn = s.apply(s_p, **x)\n",
    "            y_student = jnp.argmax(y_student, axis=-1) if task_type == \"classification\" else y_student\n",
    "            student_expl, _ = student_explainer.apply(s_e_p, x, student_attn)\n",
    "            # student_attn = np.asarray(jnp.stack(student_attn['attentions']).transpose([1, 0, 2, 3, 4]))\n",
    "        \n",
    "        # convert everything to lists\n",
    "        batch_ids = x['input_ids'].tolist()\n",
    "        batch_tokens = [tokenizer.convert_ids_to_tokens(ids) for ids in batch_ids]\n",
    "        batch_masks = [[tk.startswith('▁') for tk in tokens] for tokens in batch_tokens]\n",
    "        batch_expls = teacher_expl.tolist()\n",
    "        \n",
    "        # filter out pad\n",
    "        batch_valid_len = x['attention_mask'].sum(-1).tolist()\n",
    "        for i in range(len(batch_valid_len)):\n",
    "            n = batch_valid_len[i]\n",
    "            batch_ids[i] = batch_ids[i][:n]\n",
    "            batch_tokens[i] = batch_tokens[i][:n]\n",
    "            batch_masks[i] = batch_masks[i][:n]\n",
    "            batch_expls[i] = batch_expls[i][:n]\n",
    "        \n",
    "        all_tokens.extend(batch_tokens)\n",
    "        all_masks.extend(batch_masks)\n",
    "        all_explanations.extend(batch_expls)\n",
    "        all_outputs.extend(y_teacher.tolist())\n",
    "        \n",
    "    return all_tokens, all_masks, all_explanations, all_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ead4a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_tokens, valid_masks, valid_explanations, valid_outputs = get_expls(\n",
    "    valid_data, teacher, teacher_params, teacher_explainer, teacher_explainer_params \n",
    ")\n",
    "list(map(len, [valid_tokens, valid_masks, valid_explanations, valid_outputs]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2ab6508",
   "metadata": {},
   "source": [
    "### Aggregate scores for word pieces in SRC and MT independently"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31a1ae7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from utils import aggregate_pieces\n",
    "\n",
    "def get_src_and_mt_explanations(all_tokens, all_fp_masks, all_explanations, reduction):\n",
    "    src_expls = []\n",
    "    mt_expls = []\n",
    "    src_pieces = []\n",
    "    mt_pieces = []\n",
    "    for tokens, expl, fp_mask in zip(all_tokens, all_explanations, all_fp_masks):\n",
    "        # split data into src and mt (assuming \"<s> src </s> mt </s>\" format without CLS for mt) \n",
    "        src_len = tokens.index(tokenizer.sep_token) + 1\n",
    "        src_tokens, mt_tokens = tokens[:src_len], tokens[src_len:]\n",
    "        src_expl, mt_expl = expl[:src_len], expl[src_len:]\n",
    "        src_fp_mask, mt_fp_mask = fp_mask[:src_len], fp_mask[src_len:]\n",
    "        \n",
    "        # aggregate word pieces scores (use my old good torch function)\n",
    "        agg_src_expl = aggregate_pieces(torch.tensor(src_expl), torch.tensor(src_fp_mask), reduction)\n",
    "        agg_mt_expl = aggregate_pieces(torch.tensor(mt_expl), torch.tensor(mt_fp_mask), reduction)\n",
    "        \n",
    "        # remove <s> and </s> from src\n",
    "        agg_src_expl = agg_src_expl.tolist()[1:-1]\n",
    "        # remove </s> from mt\n",
    "        agg_mt_expl = agg_mt_expl.tolist()[:-1]\n",
    "        \n",
    "        src_pieces.append(src_tokens)\n",
    "        mt_pieces.append(mt_tokens)\n",
    "        src_expls.append(agg_src_expl)\n",
    "        mt_expls.append(agg_mt_expl)\n",
    "    return src_expls, mt_expls, src_pieces, mt_pieces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea29155a",
   "metadata": {},
   "outputs": [],
   "source": [
    "reduction = 'sum'  # first, sum, mean, max\n",
    "src_expls, mt_expls, src_pieces, mt_pieces = get_src_and_mt_explanations(\n",
    "    valid_tokens, valid_masks, valid_explanations, reduction=reduction\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99616e11",
   "metadata": {},
   "source": [
    "## Evaluating explanations by comparing explanations with word-level QE tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "874d3715",
   "metadata": {},
   "outputs": [],
   "source": [
    "gold_src_tokens = [inp['original'].split() for inp in valid_data]\n",
    "gold_mt_tokens = [inp['translation'].split() for inp in valid_data]\n",
    "gold_expls_src = [inp['src_tags'] for inp in valid_data]\n",
    "gold_expls_mt = [inp['mt_tags'] for inp in valid_data]\n",
    "gold_scores = [inp['z_mean'] for inp in valid_data]\n",
    "\n",
    "pred_expls_src = src_expls\n",
    "pred_expls_mt = mt_expls\n",
    "pred_scores = unroll(valid_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0a6069c",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = evaluate_sentence_level(gold_scores, pred_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fad2aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = evaluate_word_level(gold_expls_src, pred_expls_src)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95bfff3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = evaluate_word_level(gold_expls_mt, pred_expls_mt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ae28f40",
   "metadata": {},
   "source": [
    "## Evaluate all LPs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ec137a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_diff_seq_len(gold, pred):\n",
    "    new_pred, new_gold = [], []\n",
    "    t = 0\n",
    "    for p, g in zip(pred, gold):\n",
    "        if len(p) == len(g):\n",
    "            new_pred.append(p)\n",
    "            new_gold.append(g)\n",
    "        else:\n",
    "            t += 1\n",
    "    print('filtered:', t)\n",
    "    return new_gold, new_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14afc36c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_plausibility_all_lps(t, t_p, t_e, t_e_p, split='dev', is_grad_based=False):\n",
    "    langpairs = [\"en-de\", \"en-zh\", \"et-en\", \"ne-en\", \"ro-en\", \"ru-en\", \"all\"]\n",
    "    for lp in langpairs:\n",
    "        if lp == \"all\":\n",
    "            data = read_data_all(langpairs[:-1], split)\n",
    "        else:\n",
    "            data = read_data(lp, split)\n",
    "        valid_tokens, valid_masks, valid_explanations, valid_outputs = get_expls(\n",
    "            data, t, t_p, t_e, t_e_p, is_grad_based=is_grad_based\n",
    "        )\n",
    "        print('')\n",
    "        print(lp)\n",
    "        print('----------')\n",
    "        src_expls, mt_expls, src_pieces, mt_pieces = get_src_and_mt_explanations(\n",
    "            valid_tokens, valid_masks, valid_explanations, reduction='sum'\n",
    "        )\n",
    "        gold_src_tokens = [inp['original'].split() for inp in data]\n",
    "        gold_mt_tokens = [inp['translation'].split() for inp in data]\n",
    "        gold_expls_src = [inp['src_tags'] for inp in data]\n",
    "        gold_expls_mt = [inp['mt_tags'] for inp in data]\n",
    "        gold_scores = [inp['z_mean'] for inp in data]\n",
    "        pred_expls_src = src_expls\n",
    "        pred_expls_mt = mt_expls\n",
    "        pred_scores = unroll(valid_outputs)\n",
    "        gold_expls_src, pred_expls_src = filter_diff_seq_len(gold_expls_src, pred_expls_src)\n",
    "        gold_expls_mt, pred_expls_mt = filter_diff_seq_len(gold_expls_mt, pred_expls_mt)\n",
    "        evaluate_sentence_level(gold_scores, pred_scores)\n",
    "        evaluate_word_level(gold_expls_src, pred_expls_src)\n",
    "        evaluate_word_level(gold_expls_mt, pred_expls_mt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37d8adb4",
   "metadata": {},
   "source": [
    "### meta-learned explainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b2dcda8",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_plausibility_all_lps(\n",
    "    teacher, \n",
    "    teacher_params, \n",
    "    teacher_explainer, \n",
    "    teacher_explainer_params, \n",
    "    split='dev'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41148ff6",
   "metadata": {},
   "source": [
    "### all attention layers and heads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a07e110",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_plausibility_all_lps(\n",
    "    teacher, \n",
    "    teacher_params, \n",
    "    teacher_explainer_non_trained, \n",
    "    teacher_explainer_params_non_trained,\n",
    "    split='dev'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5115340",
   "metadata": {},
   "source": [
    "### gradient x input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f2af246",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_plausibility_all_lps(\n",
    "    teacher, \n",
    "    teacher_params, \n",
    "    input_gradient_teacher_explainer, \n",
    "    input_gradient_teacher_explainer_params,\n",
    "    split='dev',\n",
    "    is_grad_based=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "341c6001",
   "metadata": {},
   "source": [
    "### integrated gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d62e91ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_plausibility_all_lps(\n",
    "    teacher, \n",
    "    teacher_params, \n",
    "    int_gradient_teacher_explainer, \n",
    "    int_gradient_teacher_explainer_params,\n",
    "    split='dev',\n",
    "    is_grad_based=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2153c55",
   "metadata": {},
   "source": [
    "### best attention layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15514746",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_plausibility_all_lps(\n",
    "    teacher, \n",
    "    teacher_params, \n",
    "    best_layer_teacher_explainer, \n",
    "    best_layer_teacher_explainer_params,\n",
    "    split='dev'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6926720a",
   "metadata": {},
   "source": [
    "### best attention head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3734617c",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_plausibility_all_lps(\n",
    "    teacher, \n",
    "    teacher_params, \n",
    "    best_head_teacher_explainer, \n",
    "    best_head_teacher_explainer_params,\n",
    "    split='dev'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7defb4d7",
   "metadata": {},
   "source": [
    "### last layer attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0179a39c",
   "metadata": {},
   "outputs": [],
   "source": [
    "flax.linen.softmax(teacher_params['params']['scalarmix']['coeffs'])  # first item is the embedding layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0fea930",
   "metadata": {},
   "outputs": [],
   "source": [
    "flax.linen.softmax(teacher_params['params']['scalarmix']['coeffs']).argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91fd0c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_layer_teacher_explainer_params={\n",
    "    'normalize_head_coeffs': 'sparsemax',\n",
    "    'normalizer_fn': 'softmax',\n",
    "    'aggregator_idx': 'mean',\n",
    "    'aggregator_dim': 'row',\n",
    "    'init_fn': 'uniform',\n",
    "    'layer_idx': 11,  #9, None\n",
    "    'head_idx': None,  #5, None\n",
    "}\n",
    "best_layer_teacher_explainer, best_layer_teacher_explainer_params = create_explainer(\n",
    "    key=next(keyseq), \n",
    "    inputs=dummy_inputs, \n",
    "    state=dummy_state, \n",
    "    explainer_type='attention_explainer', \n",
    "    explainer_args=best_layer_teacher_explainer_params\n",
    ")\n",
    "eval_plausibility_all_lps(\n",
    "    teacher, \n",
    "    teacher_params, \n",
    "    best_layer_teacher_explainer, \n",
    "    best_layer_teacher_explainer_params,\n",
    "    split='dev'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae36857a",
   "metadata": {},
   "source": [
    "## Plotting the distribution of predictions and AUC scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f1cf53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define options for seaborn\n",
    "custom_params = {\n",
    "    'axes.spines.right': False,\n",
    "    'axes.spines.top': False,\n",
    "    'grid.color': '.85',\n",
    "    'grid.linestyle': ':'\n",
    "}\n",
    "_ = sns.set_theme(style='whitegrid', rc=custom_params),\n",
    "\n",
    "def plot_da_vs_expl_metric(metric_fn, das, e_golds, e_preds):\n",
    "    x = []\n",
    "    y = []\n",
    "    for da, gold, pred in zip(das, e_golds, e_preds):\n",
    "        if sum(gold) == 0 or sum(gold) == len(gold):\n",
    "            continue\n",
    "        y.append(metric_fn(gold, pred))\n",
    "        x.append(da)\n",
    "    x = np.array(x)\n",
    "    y = np.array(y)\n",
    "    fig, axs = plt.subplots(1, 3, figsize=(16, 4))\n",
    "    sns.histplot(x=x, y=y, ax=axs[0])\n",
    "    axs[0].set_xlabel('da')\n",
    "    axs[0].set_ylabel(str(metric_fn).split()[1])\n",
    "    sns.histplot(x, bins=20, ax=axs[1])\n",
    "    axs[1].set_xlabel('da')\n",
    "    sns.histplot(y, bins=20, ax=axs[2])\n",
    "    axs[2].set_xlabel(str(metric_fn).split()[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a0b03c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot predicted DA vs AUC for src and mt\n",
    "plot_da_vs_expl_metric(roc_auc_score, pred_scores, gold_expls_src, pred_expls_src)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e42f92e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_da_vs_expl_metric(roc_auc_score, pred_scores, gold_expls_mt, pred_expls_mt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e659af49",
   "metadata": {},
   "source": [
    "## Check results for all layers (slooow -> very inefficient)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "347adcb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer_id in range(12):\n",
    "    valid_tokens, valid_masks, valid_explanations, valid_outputs = get_explanations(\n",
    "        valid_data, strategy='layer_average', layer_id=layer_id\n",
    "    )\n",
    "    src_expls, mt_expls, src_pieces, mt_pieces = get_src_and_mt_explanations(\n",
    "        valid_tokens, valid_masks, valid_explanations, reduction='sum'\n",
    "    )\n",
    "    print('LAYER: {}'.format(layer_id))\n",
    "    _ = evaluate_word_level(gold_expls_src, src_expls)\n",
    "    _ = evaluate_word_level(gold_expls_mt, mt_expls)\n",
    "    print('---')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23aa5101",
   "metadata": {},
   "source": [
    "## Check results for all heads in all layers ((very slow)^2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37f9e36b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer_id in range(12):\n",
    "    for head_id in range(12):\n",
    "        valid_tokens, valid_masks, valid_explanations, valid_outputs = get_explanations(\n",
    "            valid_data, strategy='layer_head', layer_id=layer_id, head_id=head_id\n",
    "        )\n",
    "        src_expls, mt_expls, src_pieces, mt_pieces = get_src_and_mt_explanations(\n",
    "            valid_tokens, valid_masks, valid_explanations, reduction='sum'\n",
    "        )\n",
    "        print('LAYER: {} | HEAD: {}'.format(layer_id, head_id))\n",
    "        _ = evaluate_word_level(gold_expls_src, src_expls)\n",
    "        _ = evaluate_word_level(gold_expls_mt, mt_expls)\n",
    "        print('---')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
