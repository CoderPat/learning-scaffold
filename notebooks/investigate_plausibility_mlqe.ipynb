{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0f173f6e",
   "metadata": {},
   "source": [
    "set cuda id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e5442597",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
      "env: CUDA_VISIBLE_DEVICES=4\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
    "%env CUDA_VISIBLE_DEVICES=4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0343ff12",
   "metadata": {},
   "source": [
    "Install dependencies for computing metrics and plots:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7b7502e9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#!pip3 install numpy scipy pandas seaborn matplotlib sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6e1ab61",
   "metadata": {},
   "source": [
    "## Basic imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "111e491d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import flax\n",
    "from entmax_jax import sparsemax\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from IPython.display import display, HTML\n",
    "from functools import partial\n",
    "import json\n",
    "from entmax_jax.activations import sparsemax, entmax15\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "\n",
    "from meta_expl.explainers import load_explainer\n",
    "from meta_expl.models import load_model\n",
    "from meta_expl.data.mlqe import dataloader\n",
    "\n",
    "from evaluate_explanations import evaluate_word_level, evaluate_sentence_level, aggregate_pieces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "696c7a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data utils\n",
    "def unroll(list_of_lists):\n",
    "    return [e for ell in list_of_lists for e in ell]\n",
    "\n",
    "def read_data(lp, split='dev'):\n",
    "    def tags_to_ints(line):\n",
    "        return list(map(int, line.strip().replace('OK', '0').replace('BAD', '1').split()))\n",
    "    data = {\n",
    "        'original': [line.strip() for line in open('data/mlqepe/{}/{}.src'.format(lp, split), 'r')],\n",
    "        'translation': [line.strip() for line in open('data/mlqepe/{}/{}.mt'.format(lp, split), 'r')],\n",
    "        'z_mean': [float(line.strip()) for line in open('data/mlqepe/{}/{}.da'.format(lp, split), 'r')],\n",
    "        'src_tags': [tags_to_ints(line) for line in open('data/mlqepe/{}/{}.src-tags'.format(lp, split), 'r')],\n",
    "        'mt_tags': [tags_to_ints(line) for line in open('data/mlqepe/{}/{}.tgt-tags'.format(lp, split), 'r')]\n",
    "    }\n",
    "    data['da'] = data['z_mean']\n",
    "    data = [dict(zip(data.keys(), v)) for v in list(zip(*data.values()))]\n",
    "    return data\n",
    "\n",
    "def read_data_all(lps, split='dev'):\n",
    "    data = {\n",
    "        'original': [],\n",
    "        'translation': [],\n",
    "        'z_mean': [],\n",
    "        'src_tags': [],\n",
    "        'mt_tags': [],\n",
    "    }\n",
    "    data['da'] = data['z_mean']\n",
    "    for lp in lps:\n",
    "        ell = read_data(lp, split)\n",
    "        for key in data.keys():\n",
    "            data[key].extend([d[key] for d in ell])\n",
    "    data = [dict(zip(data.keys(), v)) for v in list(zip(*data.values()))]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0051472",
   "metadata": {},
   "source": [
    "## Define args and load stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e77dafcf",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# arguments\n",
    "arch = 'xlm-roberta-base'\n",
    "arch_mtl = 'xlm-r'\n",
    "setup = 'no_teacher'  # \"no_teacher\", \"static_teacher\", \"learnable_teacher\"\n",
    "# langpairs = [\"en-de\", \"en-zh\", \"et-en\", \"ne-en\", \"ro-en\", \"ru-en\"]\n",
    "lp = 'ro-en'\n",
    "max_len = 256\n",
    "batch_size = 16\n",
    "seed = 1\n",
    "sep_token = \"</s>\" if 'xlm' in arch else \"[SEP]\"\n",
    "dataloader = partial(dataloader, sep_token=sep_token)\n",
    "num_classes = 1\n",
    "task_type = \"regression\"\n",
    "teacher_dir = 'data/mlqe-xlmr-models/teacher_dir'\n",
    "explainer_dir = 'data/mlqe-xlmr-models/teacher_expl_dir'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a323ee16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16, 256)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create dummy inputs for model instantiation\n",
    "input_ids = jnp.ones((batch_size, max_len), jnp.int32)\n",
    "dummy_inputs = {\n",
    "    \"input_ids\": input_ids,\n",
    "    \"attention_mask\": jnp.ones_like(input_ids),\n",
    "    \"token_type_ids\": jnp.arange(jnp.atleast_2d(input_ids).shape[-1]),\n",
    "    \"position_ids\": jnp.ones_like(input_ids),\n",
    "}\n",
    "dummy_inputs['input_ids'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1f4f9ad",
   "metadata": {},
   "source": [
    "### load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1c07f5c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "train_data = read_data(lp, \"train\")\n",
    "valid_data = read_data(lp, \"dev\")\n",
    "test_data = read_data(lp, \"test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f90ea756",
   "metadata": {},
   "source": [
    "### load tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bbf471df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import XLMRobertaTokenizerFast\n",
    "tokenizer = XLMRobertaTokenizerFast.from_pretrained(arch)\n",
    "cls_id = tokenizer.cls_token_id\n",
    "sep_id = tokenizer.sep_token_id\n",
    "pad_id = tokenizer.pad_token_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7df6d85",
   "metadata": {},
   "source": [
    "### load model and explainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "478ee21f",
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher, teacher_params, dummy_state = load_model(teacher_dir, dummy_inputs, batch_size, max_len)\n",
    "teacher_explainer, teacher_explainer_params = load_explainer(explainer_dir, dummy_inputs, state=dummy_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f482d52e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from meta_expl.utils import PRNGSequence\n",
    "from meta_expl.explainers import create_explainer\n",
    "keyseq = PRNGSequence(11)\n",
    "teacher_explainer_params_non_trained={\n",
    "    'normalize_head_coeffs': 'sparsemax',\n",
    "    'normalizer_fn': 'softmax',\n",
    "    'aggregator_idx': 'mean',\n",
    "    'aggregator_dim': 'row',\n",
    "    'init_fn': 'uniform',\n",
    "    'layer_idx': None,\n",
    "    'head_idx': None\n",
    "}\n",
    "teacher_explainer_non_trained, teacher_explainer_params_non_trained = create_explainer(\n",
    "    key=next(keyseq),\n",
    "    inputs=dummy_inputs,\n",
    "    state=dummy_state,\n",
    "    explainer_type='attention_explainer',\n",
    "    explainer_args=teacher_explainer_params_non_trained,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fe63b22a",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_head_teacher_explainer_params={\n",
    "    'normalize_head_coeffs': 'sparsemax',\n",
    "    'normalizer_fn': 'softmax',\n",
    "    'aggregator_idx': 'mean',\n",
    "    'aggregator_dim': 'row',\n",
    "    'init_fn': 'uniform',\n",
    "    'layer_idx': 9,  #9, None\n",
    "    'head_idx': 5,  #5, None\n",
    "}\n",
    "best_head_teacher_explainer, best_head_teacher_explainer_params = create_explainer(\n",
    "    key=next(keyseq), \n",
    "    inputs=dummy_inputs, \n",
    "    state=dummy_state, \n",
    "    explainer_type='attention_explainer', \n",
    "    explainer_args=best_head_teacher_explainer_params\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2f07e2ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_layer_teacher_explainer_params={\n",
    "    'normalize_head_coeffs': 'sparsemax',\n",
    "    'normalizer_fn': 'softmax',\n",
    "    'aggregator_idx': 'mean',\n",
    "    'aggregator_dim': 'row',\n",
    "    'init_fn': 'uniform',\n",
    "    'layer_idx': 10,  #9, None\n",
    "    'head_idx': None,  #5, None\n",
    "}\n",
    "best_layer_teacher_explainer, best_layer_teacher_explainer_params = create_explainer(\n",
    "    key=next(keyseq), \n",
    "    inputs=dummy_inputs, \n",
    "    state=dummy_state, \n",
    "    explainer_type='attention_explainer', \n",
    "    explainer_args=best_layer_teacher_explainer_params\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d7ac6a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_gradient_teacher_explainer, input_gradient_teacher_explainer_params = create_explainer(\n",
    "    key=next(keyseq), \n",
    "    inputs=dummy_inputs, \n",
    "    state=dummy_state, \n",
    "    explainer_type='gradient_input_explainer', \n",
    "    model_extras={\n",
    "        \"grad_fn\": teacher.apply(\n",
    "            teacher_params, dummy_inputs, method=teacher.embeddings_grad_fn\n",
    "        )\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fbbf34ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "int_gradient_teacher_explainer, int_gradient_teacher_explainer_params = create_explainer(\n",
    "    key=next(keyseq), \n",
    "    inputs=dummy_inputs, \n",
    "    state=dummy_state, \n",
    "    explainer_type='integrated_gradients_explainer', \n",
    "    model_extras={\n",
    "        \"grad_fn\": teacher.apply(\n",
    "            teacher_params, dummy_inputs, method=teacher.embeddings_grad_fn\n",
    "        )\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2d09885",
   "metadata": {},
   "source": [
    "### look at the coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c2e0f46b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeviceArray([[0.05825656, 0.05605122, 0.06579615, 0.06052823, 0.05019351,\n",
       "              0.0858976 , 0.04817941, 0.05621345, 0.01868655, 0.02941416,\n",
       "              0.04372283, 0.05819663],\n",
       "             [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "              0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "              0.        , 0.        ],\n",
       "             [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "              0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "              0.        , 0.        ],\n",
       "             [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "              0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "              0.        , 0.        ],\n",
       "             [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "              0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "              0.0433885 , 0.        ],\n",
       "             [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "              0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "              0.        , 0.        ],\n",
       "             [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "              0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "              0.        , 0.        ],\n",
       "             [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "              0.        , 0.        , 0.        , 0.08041232, 0.09685925,\n",
       "              0.        , 0.        ],\n",
       "             [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "              0.0302523 , 0.        , 0.03107029, 0.        , 0.        ,\n",
       "              0.        , 0.        ],\n",
       "             [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "              0.04859592, 0.        , 0.        , 0.        , 0.        ,\n",
       "              0.        , 0.        ],\n",
       "             [0.        , 0.02883356, 0.        , 0.00945152, 0.        ,\n",
       "              0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "              0.        , 0.        ],\n",
       "             [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "              0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "              0.        , 0.        ]], dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sparsemax(teacher_explainer_params['params']['head_coeffs']).reshape(12, 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8a706e2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 1\n",
      "1 2\n",
      "1 3\n",
      "1 4\n",
      "1 5\n",
      "1 6\n",
      "1 7\n",
      "1 8\n",
      "1 9\n",
      "1 10\n",
      "1 11\n",
      "1 12\n",
      "5 11\n",
      "8 9\n",
      "8 10\n",
      "9 6\n",
      "9 8\n",
      "10 6\n",
      "11 2\n",
      "11 4\n"
     ]
    }
   ],
   "source": [
    "hc = sparsemax(teacher_explainer_params['params']['head_coeffs']).reshape(12, 12)\n",
    "for a, b in zip(*hc.nonzero()):\n",
    "    print(a+1, b+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "18549d54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2, 0.0),\n",
       " (3, 0.0),\n",
       " (4, 0.0),\n",
       " (6, 0.0),\n",
       " (7, 0.0),\n",
       " (12, 0.0),\n",
       " (11, 0.003190424060449004),\n",
       " (5, 0.003615708090364933),\n",
       " (10, 0.004049660172313452),\n",
       " (9, 0.005110216327011585),\n",
       " (8, 0.014772631227970123),\n",
       " (1, 0.052594687789678574)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the layers with the highest coefficients\n",
    "layer_coeffs = sparsemax(teacher_explainer_params['params']['head_coeffs']).reshape(12, 12).mean(-1).tolist()\n",
    "sorted(list(zip(list(range(1, len(layer_coeffs)+1)), layer_coeffs)), key=lambda k: k[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0a705b0",
   "metadata": {},
   "source": [
    "## Get explanations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "33bd87c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_expls(data, t, t_p, t_e, t_e_p, s=None, s_p=None, s_e=None, s_e_p=None, is_grad_based=False):\n",
    "    all_tokens = []\n",
    "    all_masks = []\n",
    "    all_explanations = []\n",
    "    all_outputs = []\n",
    "    for i, (x, y) in enumerate(dataloader(data, tokenizer, batch_size=batch_size, max_len=max_len, shuffle=False)):\n",
    "        print('{} of {}'.format(i+1, len(data) // batch_size + 1), end='\\r')\n",
    "    \n",
    "        y_teacher, teacher_attn = t.apply(t_p, **x, deterministic=True)\n",
    "        y_teacher = jnp.argmax(y_teacher, axis=-1) if task_type == \"classification\" else y_teacher\n",
    "        \n",
    "        if is_grad_based:\n",
    "            teacher_extras = {\n",
    "                \"grad_fn\": t.apply(t_p, x, method=t.embeddings_grad_fn)\n",
    "            }\n",
    "            teacher_expl, _ = t_e.apply(t_e_p, x, teacher_attn, **teacher_extras)\n",
    "        else:\n",
    "            teacher_expl, _ = t_e.apply(t_e_p, x, teacher_attn)\n",
    "        # teacher_rep = teacher_attn['hidden_states'][0][0]\n",
    "        # teacher_attn = np.asarray(jnp.stack(teacher_attn['attentions']).transpose([1, 0, 2, 3, 4]))\n",
    "        \n",
    "        if s is not None:\n",
    "            y_student, student_attn = s.apply(s_p, **x)\n",
    "            y_student = jnp.argmax(y_student, axis=-1) if task_type == \"classification\" else y_student\n",
    "            student_expl, _ = student_explainer.apply(s_e_p, x, student_attn)\n",
    "            # student_attn = np.asarray(jnp.stack(student_attn['attentions']).transpose([1, 0, 2, 3, 4]))\n",
    "        \n",
    "        # convert everything to lists\n",
    "        batch_ids = x['input_ids'].tolist()\n",
    "        batch_tokens = [tokenizer.convert_ids_to_tokens(ids) for ids in batch_ids]\n",
    "        batch_masks = [[tk.startswith('▁') for tk in tokens] for tokens in batch_tokens]\n",
    "        batch_expls = teacher_expl.tolist()\n",
    "        \n",
    "        # filter out pad\n",
    "        batch_valid_len = x['attention_mask'].sum(-1).tolist()\n",
    "        for i in range(len(batch_valid_len)):\n",
    "            n = batch_valid_len[i]\n",
    "            batch_ids[i] = batch_ids[i][:n]\n",
    "            batch_tokens[i] = batch_tokens[i][:n]\n",
    "            batch_masks[i] = batch_masks[i][:n]\n",
    "            batch_expls[i] = batch_expls[i][:n]\n",
    "        \n",
    "        all_tokens.extend(batch_tokens)\n",
    "        all_masks.extend(batch_masks)\n",
    "        all_explanations.extend(batch_expls)\n",
    "        all_outputs.extend(y_teacher.tolist())\n",
    "        \n",
    "    return all_tokens, all_masks, all_explanations, all_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "17ead4a0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63 of 63\r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1000, 1000, 1000, 1000]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_tokens, valid_masks, valid_explanations, valid_outputs = get_expls(\n",
    "    valid_data, teacher, teacher_params, teacher_explainer, teacher_explainer_params \n",
    ")\n",
    "list(map(len, [valid_tokens, valid_masks, valid_explanations, valid_outputs]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2ab6508",
   "metadata": {},
   "source": [
    "### Aggregate scores for word pieces in SRC and MT independently"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "31a1ae7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from utils import aggregate_pieces\n",
    "\n",
    "def get_src_and_mt_explanations(all_tokens, all_fp_masks, all_explanations, reduction):\n",
    "    src_expls = []\n",
    "    mt_expls = []\n",
    "    src_pieces = []\n",
    "    mt_pieces = []\n",
    "    for tokens, expl, fp_mask in zip(all_tokens, all_explanations, all_fp_masks):\n",
    "        # split data into src and mt (assuming \"<s> src </s> mt </s>\" format without CLS for mt) \n",
    "        src_len = tokens.index(tokenizer.sep_token) + 1\n",
    "        src_tokens, mt_tokens = tokens[:src_len], tokens[src_len:]\n",
    "        src_expl, mt_expl = expl[:src_len], expl[src_len:]\n",
    "        src_fp_mask, mt_fp_mask = fp_mask[:src_len], fp_mask[src_len:]\n",
    "        \n",
    "        # aggregate word pieces scores (use my old good torch function)\n",
    "        agg_src_expl = aggregate_pieces(torch.tensor(src_expl), torch.tensor(src_fp_mask), reduction)\n",
    "        agg_mt_expl = aggregate_pieces(torch.tensor(mt_expl), torch.tensor(mt_fp_mask), reduction)\n",
    "        \n",
    "        # remove <s> and </s> from src\n",
    "        agg_src_expl = agg_src_expl.tolist()[1:-1]\n",
    "        # remove </s> from mt\n",
    "        agg_mt_expl = agg_mt_expl.tolist()[:-1]\n",
    "        \n",
    "        src_pieces.append(src_tokens)\n",
    "        mt_pieces.append(mt_tokens)\n",
    "        src_expls.append(agg_src_expl)\n",
    "        mt_expls.append(agg_mt_expl)\n",
    "    return src_expls, mt_expls, src_pieces, mt_pieces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ea29155a",
   "metadata": {},
   "outputs": [],
   "source": [
    "reduction = 'sum'  # first, sum, mean, max\n",
    "src_expls, mt_expls, src_pieces, mt_pieces = get_src_and_mt_explanations(\n",
    "    valid_tokens, valid_masks, valid_explanations, reduction=reduction\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99616e11",
   "metadata": {},
   "source": [
    "## Evaluating explanations by comparing explanations with word-level QE tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "874d3715",
   "metadata": {},
   "outputs": [],
   "source": [
    "gold_src_tokens = [inp['original'].split() for inp in valid_data]\n",
    "gold_mt_tokens = [inp['translation'].split() for inp in valid_data]\n",
    "gold_expls_src = [inp['src_tags'] for inp in valid_data]\n",
    "gold_expls_mt = [inp['mt_tags'] for inp in valid_data]\n",
    "gold_scores = [inp['z_mean'] for inp in valid_data]\n",
    "\n",
    "pred_expls_src = src_expls\n",
    "pred_expls_mt = mt_expls\n",
    "pred_scores = unroll(valid_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a0a6069c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pearson: 0.7941\n",
      "Spearman: 0.7420\n",
      "MAE: 0.5030\n",
      "RMSE: 0.6408\n"
     ]
    }
   ],
   "source": [
    "_ = evaluate_sentence_level(gold_scores, pred_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0fad2aef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC score: 0.7050\n",
      "AP score: 0.5724\n",
      "Recall at top-K: 0.4449\n"
     ]
    }
   ],
   "source": [
    "_ = evaluate_word_level(gold_expls_src, pred_expls_src)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "95bfff3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC score: 0.7028\n",
      "AP score: 0.5823\n",
      "Recall at top-K: 0.4555\n"
     ]
    }
   ],
   "source": [
    "_ = evaluate_word_level(gold_expls_mt, pred_expls_mt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ae28f40",
   "metadata": {},
   "source": [
    "## Evaluate all LPs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4ec137a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_diff_seq_len(gold, pred):\n",
    "    new_pred, new_gold = [], []\n",
    "    t = 0\n",
    "    for p, g in zip(pred, gold):\n",
    "        if len(p) == len(g):\n",
    "            new_pred.append(p)\n",
    "            new_gold.append(g)\n",
    "        else:\n",
    "            t += 1\n",
    "    print('filtered:', t)\n",
    "    return new_gold, new_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "14afc36c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_plausibility_all_lps(t, t_p, t_e, t_e_p, split='dev', is_grad_based=False):\n",
    "    langpairs = [\"en-de\", \"en-zh\", \"et-en\", \"ne-en\", \"ro-en\", \"ru-en\", \"all\"]\n",
    "    for lp in langpairs:\n",
    "        if lp == \"all\":\n",
    "            data = read_data_all(langpairs[:-1], split)\n",
    "        else:\n",
    "            data = read_data(lp, split)\n",
    "        valid_tokens, valid_masks, valid_explanations, valid_outputs = get_expls(\n",
    "            data, t, t_p, t_e, t_e_p, is_grad_based=is_grad_based\n",
    "        )\n",
    "        print('')\n",
    "        print(lp)\n",
    "        print('----------')\n",
    "        src_expls, mt_expls, src_pieces, mt_pieces = get_src_and_mt_explanations(\n",
    "            valid_tokens, valid_masks, valid_explanations, reduction='sum'\n",
    "        )\n",
    "        gold_src_tokens = [inp['original'].split() for inp in data]\n",
    "        gold_mt_tokens = [inp['translation'].split() for inp in data]\n",
    "        gold_expls_src = [inp['src_tags'] for inp in data]\n",
    "        gold_expls_mt = [inp['mt_tags'] for inp in data]\n",
    "        gold_scores = [inp['z_mean'] for inp in data]\n",
    "        pred_expls_src = src_expls\n",
    "        pred_expls_mt = mt_expls\n",
    "        pred_scores = unroll(valid_outputs)\n",
    "        gold_expls_src, pred_expls_src = filter_diff_seq_len(gold_expls_src, pred_expls_src)\n",
    "        gold_expls_mt, pred_expls_mt = filter_diff_seq_len(gold_expls_mt, pred_expls_mt)\n",
    "        evaluate_sentence_level(gold_scores, pred_scores)\n",
    "        evaluate_word_level(gold_expls_src, pred_expls_src)\n",
    "        evaluate_word_level(gold_expls_mt, pred_expls_mt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37d8adb4",
   "metadata": {},
   "source": [
    "### meta-learned explainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8b2dcda8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63 of 63\n",
      "en-de\n",
      "----------\n",
      "filtered: 0\n",
      "filtered: 0\n",
      "Pearson: 0.4250\n",
      "Spearman: 0.4282\n",
      "MAE: 0.5056\n",
      "RMSE: 0.6900\n",
      "AUC score: 0.6426\n",
      "AP score: 0.4733\n",
      "Recall at top-K: 0.3470\n",
      "AUC score: 0.6534\n",
      "AP score: 0.5085\n",
      "Recall at top-K: 0.3781\n",
      "63 of 63\n",
      "en-zh\n",
      "----------\n",
      "filtered: 0\n",
      "filtered: 0\n",
      "Pearson: 0.4491\n",
      "Spearman: 0.4538\n",
      "MAE: 0.5167\n",
      "RMSE: 0.6402\n",
      "AUC score: 0.6808\n",
      "AP score: 0.5521\n",
      "Recall at top-K: 0.4279\n",
      "AUC score: 0.5191\n",
      "AP score: 0.4727\n",
      "Recall at top-K: 0.3612\n",
      "63 of 63\n",
      "et-en\n",
      "----------\n",
      "filtered: 0\n",
      "filtered: 0\n",
      "Pearson: 0.6332\n",
      "Spearman: 0.6368\n",
      "MAE: 0.5586\n",
      "RMSE: 0.6877\n",
      "AUC score: 0.6563\n",
      "AP score: 0.5336\n",
      "Recall at top-K: 0.4050\n",
      "AUC score: 0.6423\n",
      "AP score: 0.5209\n",
      "Recall at top-K: 0.4038\n",
      "63 of 63\n",
      "ne-en\n",
      "----------\n",
      "filtered: 0\n",
      "filtered: 0\n",
      "Pearson: 0.6564\n",
      "Spearman: 0.6537\n",
      "MAE: 0.5005\n",
      "RMSE: 0.6361\n",
      "AUC score: 0.6564\n",
      "AP score: 0.7447\n",
      "Recall at top-K: 0.6555\n",
      "AUC score: 0.5409\n",
      "AP score: 0.7359\n",
      "Recall at top-K: 0.6748\n",
      "63 of 63\n",
      "ro-en\n",
      "----------\n",
      "filtered: 0\n",
      "filtered: 0\n",
      "Pearson: 0.7941\n",
      "Spearman: 0.7420\n",
      "MAE: 0.5030\n",
      "RMSE: 0.6408\n",
      "AUC score: 0.7050\n",
      "AP score: 0.5724\n",
      "Recall at top-K: 0.4449\n",
      "AUC score: 0.7028\n",
      "AP score: 0.5823\n",
      "Recall at top-K: 0.4555\n",
      "63 of 63\n",
      "ru-en\n",
      "----------\n",
      "filtered: 0\n",
      "filtered: 1\n",
      "Pearson: 0.6019\n",
      "Spearman: 0.5525\n",
      "MAE: 0.5469\n",
      "RMSE: 0.7602\n",
      "AUC score: 0.6084\n",
      "AP score: 0.5580\n",
      "Recall at top-K: 0.4197\n",
      "AUC score: 0.5376\n",
      "AP score: 0.4985\n",
      "Recall at top-K: 0.3734\n",
      "375 of 376\n",
      "all\n",
      "----------\n",
      "filtered: 0\n",
      "filtered: 1\n",
      "Pearson: 0.0497\n",
      "Spearman: 0.0504\n",
      "MAE: 0.7030\n",
      "RMSE: 0.8937\n",
      "AUC score: 0.6607\n",
      "AP score: 0.5840\n",
      "Recall at top-K: 0.4645\n",
      "AUC score: 0.5990\n",
      "AP score: 0.5664\n",
      "Recall at top-K: 0.4586\n"
     ]
    }
   ],
   "source": [
    "eval_plausibility_all_lps(\n",
    "    teacher, \n",
    "    teacher_params, \n",
    "    teacher_explainer, \n",
    "    teacher_explainer_params, \n",
    "    split='dev'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41148ff6",
   "metadata": {},
   "source": [
    "### all attention layers and heads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9a07e110",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63 of 63\n",
      "en-de\n",
      "----------\n",
      "filtered: 0\n",
      "filtered: 0\n",
      "Pearson: 0.4250\n",
      "Spearman: 0.4282\n",
      "MAE: 0.5056\n",
      "RMSE: 0.6900\n",
      "AUC score: 0.6032\n",
      "AP score: 0.3703\n",
      "Recall at top-K: 0.2211\n",
      "AUC score: 0.6302\n",
      "AP score: 0.4796\n",
      "Recall at top-K: 0.3478\n",
      "63 of 63\n",
      "en-zh\n",
      "----------\n",
      "filtered: 0\n",
      "filtered: 0\n",
      "Pearson: 0.4491\n",
      "Spearman: 0.4538\n",
      "MAE: 0.5167\n",
      "RMSE: 0.6402\n",
      "AUC score: 0.6793\n",
      "AP score: 0.5264\n",
      "Recall at top-K: 0.4004\n",
      "AUC score: 0.5152\n",
      "AP score: 0.4522\n",
      "Recall at top-K: 0.3411\n",
      "63 of 63\n",
      "et-en\n",
      "----------\n",
      "filtered: 0\n",
      "filtered: 0\n",
      "Pearson: 0.6332\n",
      "Spearman: 0.6368\n",
      "MAE: 0.5586\n",
      "RMSE: 0.6877\n",
      "AUC score: 0.5966\n",
      "AP score: 0.4451\n",
      "Recall at top-K: 0.3131\n",
      "AUC score: 0.6055\n",
      "AP score: 0.4696\n",
      "Recall at top-K: 0.3580\n",
      "63 of 63\n",
      "ne-en\n",
      "----------\n",
      "filtered: 0\n",
      "filtered: 0\n",
      "Pearson: 0.6564\n",
      "Spearman: 0.6537\n",
      "MAE: 0.5005\n",
      "RMSE: 0.6361\n",
      "AUC score: 0.5823\n",
      "AP score: 0.6946\n",
      "Recall at top-K: 0.6150\n",
      "AUC score: 0.5465\n",
      "AP score: 0.7314\n",
      "Recall at top-K: 0.6822\n",
      "63 of 63\n",
      "ro-en\n",
      "----------\n",
      "filtered: 0\n",
      "filtered: 0\n",
      "Pearson: 0.7941\n",
      "Spearman: 0.7420\n",
      "MAE: 0.5030\n",
      "RMSE: 0.6408\n",
      "AUC score: 0.6642\n",
      "AP score: 0.4821\n",
      "Recall at top-K: 0.3596\n",
      "AUC score: 0.6968\n",
      "AP score: 0.5472\n",
      "Recall at top-K: 0.4192\n",
      "63 of 63\n",
      "ru-en\n",
      "----------\n",
      "filtered: 0\n",
      "filtered: 1\n",
      "Pearson: 0.6019\n",
      "Spearman: 0.5525\n",
      "MAE: 0.5469\n",
      "RMSE: 0.7602\n",
      "AUC score: 0.6173\n",
      "AP score: 0.5351\n",
      "Recall at top-K: 0.3851\n",
      "AUC score: 0.5494\n",
      "AP score: 0.5051\n",
      "Recall at top-K: 0.3805\n",
      "375 of 376\n",
      "all\n",
      "----------\n",
      "filtered: 0\n",
      "filtered: 1\n",
      "Pearson: 0.0497\n",
      "Spearman: 0.0504\n",
      "MAE: 0.7030\n",
      "RMSE: 0.8937\n",
      "AUC score: 0.6207\n",
      "AP score: 0.5192\n",
      "Recall at top-K: 0.3970\n",
      "AUC score: 0.5889\n",
      "AP score: 0.5427\n",
      "Recall at top-K: 0.4383\n"
     ]
    }
   ],
   "source": [
    "eval_plausibility_all_lps(\n",
    "    teacher, \n",
    "    teacher_params, \n",
    "    teacher_explainer_non_trained, \n",
    "    teacher_explainer_params_non_trained,\n",
    "    split='dev'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5115340",
   "metadata": {},
   "source": [
    "### gradient x input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3f2af246",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63 of 63\n",
      "en-de\n",
      "----------\n",
      "filtered: 0\n",
      "filtered: 0\n",
      "Pearson: 0.4250\n",
      "Spearman: 0.4282\n",
      "MAE: 0.5056\n",
      "RMSE: 0.6900\n",
      "AUC score: 0.5799\n",
      "AP score: 0.4146\n",
      "Recall at top-K: 0.2876\n",
      "AUC score: 0.5952\n",
      "AP score: 0.4574\n",
      "Recall at top-K: 0.3381\n",
      "63 of 63\n",
      "en-zh\n",
      "----------\n",
      "filtered: 0\n",
      "filtered: 0\n",
      "Pearson: 0.4491\n",
      "Spearman: 0.4538\n",
      "MAE: 0.5167\n",
      "RMSE: 0.6402\n",
      "AUC score: 0.6132\n",
      "AP score: 0.4871\n",
      "Recall at top-K: 0.3530\n",
      "AUC score: 0.5061\n",
      "AP score: 0.4421\n",
      "Recall at top-K: 0.3324\n",
      "63 of 63\n",
      "et-en\n",
      "----------\n",
      "filtered: 0\n",
      "filtered: 0\n",
      "Pearson: 0.6332\n",
      "Spearman: 0.6368\n",
      "MAE: 0.5586\n",
      "RMSE: 0.6877\n",
      "AUC score: 0.6024\n",
      "AP score: 0.4689\n",
      "Recall at top-K: 0.3401\n",
      "AUC score: 0.5356\n",
      "AP score: 0.4436\n",
      "Recall at top-K: 0.3320\n",
      "63 of 63\n",
      "ne-en\n",
      "----------\n",
      "filtered: 0\n",
      "filtered: 0\n",
      "Pearson: 0.6564\n",
      "Spearman: 0.6537\n",
      "MAE: 0.5005\n",
      "RMSE: 0.6361\n",
      "AUC score: 0.6145\n",
      "AP score: 0.7128\n",
      "Recall at top-K: 0.6268\n",
      "AUC score: 0.4922\n",
      "AP score: 0.7057\n",
      "Recall at top-K: 0.6428\n",
      "63 of 63\n",
      "ro-en\n",
      "----------\n",
      "filtered: 0\n",
      "filtered: 0\n",
      "Pearson: 0.7941\n",
      "Spearman: 0.7420\n",
      "MAE: 0.5030\n",
      "RMSE: 0.6408\n",
      "AUC score: 0.6390\n",
      "AP score: 0.5066\n",
      "Recall at top-K: 0.3825\n",
      "AUC score: 0.5873\n",
      "AP score: 0.4905\n",
      "Recall at top-K: 0.3757\n",
      "63 of 63\n",
      "ru-en\n",
      "----------\n",
      "filtered: 0\n",
      "filtered: 1\n",
      "Pearson: 0.6019\n",
      "Spearman: 0.5525\n",
      "MAE: 0.5469\n",
      "RMSE: 0.7602\n",
      "AUC score: 0.5837\n",
      "AP score: 0.5234\n",
      "Recall at top-K: 0.3598\n",
      "AUC score: 0.5079\n",
      "AP score: 0.4688\n",
      "Recall at top-K: 0.3443\n",
      "375 of 376\n",
      "all\n",
      "----------\n",
      "filtered: 0\n",
      "filtered: 1\n",
      "Pearson: 0.0497\n",
      "Spearman: 0.0504\n",
      "MAE: 0.7030\n",
      "RMSE: 0.8937\n",
      "AUC score: 0.6071\n",
      "AP score: 0.5306\n",
      "Recall at top-K: 0.4079\n",
      "AUC score: 0.5350\n",
      "AP score: 0.5143\n",
      "Recall at top-K: 0.4110\n"
     ]
    }
   ],
   "source": [
    "eval_plausibility_all_lps(\n",
    "    teacher, \n",
    "    teacher_params, \n",
    "    input_gradient_teacher_explainer, \n",
    "    input_gradient_teacher_explainer_params,\n",
    "    split='dev',\n",
    "    is_grad_based=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "341c6001",
   "metadata": {},
   "source": [
    "### integrated gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d62e91ec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63 of 63\n",
      "en-de\n",
      "----------\n",
      "filtered: 0\n",
      "filtered: 0\n",
      "Pearson: 0.4250\n",
      "Spearman: 0.4282\n",
      "MAE: 0.5056\n",
      "RMSE: 0.6900\n",
      "AUC score: 0.5855\n",
      "AP score: 0.3960\n",
      "Recall at top-K: 0.2602\n",
      "AUC score: 0.6028\n",
      "AP score: 0.4574\n",
      "Recall at top-K: 0.3267\n",
      "63 of 63\n",
      "en-zh\n",
      "----------\n",
      "filtered: 0\n",
      "filtered: 0\n",
      "Pearson: 0.4491\n",
      "Spearman: 0.4538\n",
      "MAE: 0.5167\n",
      "RMSE: 0.6402\n",
      "AUC score: 0.6275\n",
      "AP score: 0.4976\n",
      "Recall at top-K: 0.3707\n",
      "AUC score: 0.4932\n",
      "AP score: 0.4519\n",
      "Recall at top-K: 0.3442\n",
      "63 of 63\n",
      "et-en\n",
      "----------\n",
      "filtered: 0\n",
      "filtered: 0\n",
      "Pearson: 0.6332\n",
      "Spearman: 0.6368\n",
      "MAE: 0.5586\n",
      "RMSE: 0.6877\n",
      "AUC score: 0.6042\n",
      "AP score: 0.4778\n",
      "Recall at top-K: 0.3446\n",
      "AUC score: 0.5212\n",
      "AP score: 0.4157\n",
      "Recall at top-K: 0.3084\n",
      "63 of 63\n",
      "ne-en\n",
      "----------\n",
      "filtered: 0\n",
      "filtered: 0\n",
      "Pearson: 0.6564\n",
      "Spearman: 0.6537\n",
      "MAE: 0.5005\n",
      "RMSE: 0.6361\n",
      "AUC score: 0.6355\n",
      "AP score: 0.7299\n",
      "Recall at top-K: 0.6406\n",
      "AUC score: 0.4848\n",
      "AP score: 0.6963\n",
      "Recall at top-K: 0.6507\n",
      "63 of 63\n",
      "ro-en\n",
      "----------\n",
      "filtered: 0\n",
      "filtered: 0\n",
      "Pearson: 0.7941\n",
      "Spearman: 0.7420\n",
      "MAE: 0.5030\n",
      "RMSE: 0.6408\n",
      "AUC score: 0.6441\n",
      "AP score: 0.5002\n",
      "Recall at top-K: 0.3800\n",
      "AUC score: 0.5853\n",
      "AP score: 0.4504\n",
      "Recall at top-K: 0.3254\n",
      "63 of 63\n",
      "ru-en\n",
      "----------\n",
      "filtered: 0\n",
      "filtered: 1\n",
      "Pearson: 0.6019\n",
      "Spearman: 0.5525\n",
      "MAE: 0.5469\n",
      "RMSE: 0.7602\n",
      "AUC score: 0.5953\n",
      "AP score: 0.5466\n",
      "Recall at top-K: 0.3971\n",
      "AUC score: 0.5133\n",
      "AP score: 0.4798\n",
      "Recall at top-K: 0.3587\n",
      "375 of 376\n",
      "all\n",
      "----------\n",
      "filtered: 0\n",
      "filtered: 1\n",
      "Pearson: 0.0497\n",
      "Spearman: 0.0504\n",
      "MAE: 0.7030\n",
      "RMSE: 0.8937\n",
      "AUC score: 0.6175\n",
      "AP score: 0.5367\n",
      "Recall at top-K: 0.4144\n",
      "AUC score: 0.5298\n",
      "AP score: 0.5033\n",
      "Recall at top-K: 0.4022\n"
     ]
    }
   ],
   "source": [
    "eval_plausibility_all_lps(\n",
    "    teacher, \n",
    "    teacher_params, \n",
    "    int_gradient_teacher_explainer, \n",
    "    int_gradient_teacher_explainer_params,\n",
    "    split='dev',\n",
    "    is_grad_based=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2153c55",
   "metadata": {},
   "source": [
    "### best attention layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "15514746",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63 of 63\n",
      "en-de\n",
      "----------\n",
      "filtered: 0\n",
      "filtered: 0\n",
      "Pearson: 0.4250\n",
      "Spearman: 0.4282\n",
      "MAE: 0.5056\n",
      "RMSE: 0.6900\n",
      "AUC score: 0.6370\n",
      "AP score: 0.4117\n",
      "Recall at top-K: 0.2774\n",
      "AUC score: 0.6468\n",
      "AP score: 0.4944\n",
      "Recall at top-K: 0.3659\n",
      "63 of 63\n",
      "en-zh\n",
      "----------\n",
      "filtered: 0\n",
      "filtered: 0\n",
      "Pearson: 0.4491\n",
      "Spearman: 0.4538\n",
      "MAE: 0.5167\n",
      "RMSE: 0.6402\n",
      "AUC score: 0.5755\n",
      "AP score: 0.4636\n",
      "Recall at top-K: 0.3471\n",
      "AUC score: 0.5258\n",
      "AP score: 0.4814\n",
      "Recall at top-K: 0.3716\n",
      "63 of 63\n",
      "et-en\n",
      "----------\n",
      "filtered: 0\n",
      "filtered: 0\n",
      "Pearson: 0.6332\n",
      "Spearman: 0.6368\n",
      "MAE: 0.5586\n",
      "RMSE: 0.6877\n",
      "AUC score: 0.6420\n",
      "AP score: 0.4908\n",
      "Recall at top-K: 0.3636\n",
      "AUC score: 0.6840\n",
      "AP score: 0.5630\n",
      "Recall at top-K: 0.4460\n",
      "63 of 63\n",
      "ne-en\n",
      "----------\n",
      "filtered: 0\n",
      "filtered: 0\n",
      "Pearson: 0.6564\n",
      "Spearman: 0.6537\n",
      "MAE: 0.5005\n",
      "RMSE: 0.6361\n",
      "AUC score: 0.6824\n",
      "AP score: 0.7523\n",
      "Recall at top-K: 0.6751\n",
      "AUC score: 0.6812\n",
      "AP score: 0.8055\n",
      "Recall at top-K: 0.7226\n",
      "63 of 63\n",
      "ro-en\n",
      "----------\n",
      "filtered: 0\n",
      "filtered: 0\n",
      "Pearson: 0.7941\n",
      "Spearman: 0.7420\n",
      "MAE: 0.5030\n",
      "RMSE: 0.6408\n",
      "AUC score: 0.7104\n",
      "AP score: 0.5566\n",
      "Recall at top-K: 0.4365\n",
      "AUC score: 0.7564\n",
      "AP score: 0.6327\n",
      "Recall at top-K: 0.5126\n",
      "63 of 63\n",
      "ru-en\n",
      "----------\n",
      "filtered: 0\n",
      "filtered: 1\n",
      "Pearson: 0.6019\n",
      "Spearman: 0.5525\n",
      "MAE: 0.5469\n",
      "RMSE: 0.7602\n",
      "AUC score: 0.6421\n",
      "AP score: 0.5488\n",
      "Recall at top-K: 0.3940\n",
      "AUC score: 0.5857\n",
      "AP score: 0.5231\n",
      "Recall at top-K: 0.3918\n",
      "375 of 376\n",
      "all\n",
      "----------\n",
      "filtered: 0\n",
      "filtered: 1\n",
      "Pearson: 0.0497\n",
      "Spearman: 0.0504\n",
      "MAE: 0.7030\n",
      "RMSE: 0.8937\n",
      "AUC score: 0.6498\n",
      "AP score: 0.5499\n",
      "Recall at top-K: 0.4329\n",
      "AUC score: 0.6521\n",
      "AP score: 0.5999\n",
      "Recall at top-K: 0.4881\n"
     ]
    }
   ],
   "source": [
    "eval_plausibility_all_lps(\n",
    "    teacher, \n",
    "    teacher_params, \n",
    "    best_layer_teacher_explainer, \n",
    "    best_layer_teacher_explainer_params,\n",
    "    split='dev'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6926720a",
   "metadata": {},
   "source": [
    "### best attention head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3734617c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63 of 63\n",
      "en-de\n",
      "----------\n",
      "filtered: 0\n",
      "filtered: 0\n",
      "Pearson: 0.4250\n",
      "Spearman: 0.4282\n",
      "MAE: 0.5056\n",
      "RMSE: 0.6900\n",
      "AUC score: 0.6727\n",
      "AP score: 0.4776\n",
      "Recall at top-K: 0.3459\n",
      "AUC score: 0.6713\n",
      "AP score: 0.5155\n",
      "Recall at top-K: 0.3882\n",
      "63 of 63\n",
      "en-zh\n",
      "----------\n",
      "filtered: 0\n",
      "filtered: 0\n",
      "Pearson: 0.4491\n",
      "Spearman: 0.4538\n",
      "MAE: 0.5167\n",
      "RMSE: 0.6402\n",
      "AUC score: 0.5591\n",
      "AP score: 0.4675\n",
      "Recall at top-K: 0.3478\n",
      "AUC score: 0.5385\n",
      "AP score: 0.4850\n",
      "Recall at top-K: 0.3742\n",
      "63 of 63\n",
      "et-en\n",
      "----------\n",
      "filtered: 0\n",
      "filtered: 0\n",
      "Pearson: 0.6332\n",
      "Spearman: 0.6368\n",
      "MAE: 0.5586\n",
      "RMSE: 0.6877\n",
      "AUC score: 0.6960\n",
      "AP score: 0.5576\n",
      "Recall at top-K: 0.4243\n",
      "AUC score: 0.6961\n",
      "AP score: 0.5714\n",
      "Recall at top-K: 0.4589\n",
      "63 of 63\n",
      "ne-en\n",
      "----------\n",
      "filtered: 0\n",
      "filtered: 0\n",
      "Pearson: 0.6564\n",
      "Spearman: 0.6537\n",
      "MAE: 0.5005\n",
      "RMSE: 0.6361\n",
      "AUC score: 0.6956\n",
      "AP score: 0.7635\n",
      "Recall at top-K: 0.6817\n",
      "AUC score: 0.6919\n",
      "AP score: 0.8145\n",
      "Recall at top-K: 0.7285\n",
      "63 of 63\n",
      "ro-en\n",
      "----------\n",
      "filtered: 0\n",
      "filtered: 0\n",
      "Pearson: 0.7941\n",
      "Spearman: 0.7420\n",
      "MAE: 0.5030\n",
      "RMSE: 0.6408\n",
      "AUC score: 0.7341\n",
      "AP score: 0.5964\n",
      "Recall at top-K: 0.4741\n",
      "AUC score: 0.7470\n",
      "AP score: 0.6215\n",
      "Recall at top-K: 0.5038\n",
      "63 of 63\n",
      "ru-en\n",
      "----------\n",
      "filtered: 0\n",
      "filtered: 1\n",
      "Pearson: 0.6019\n",
      "Spearman: 0.5525\n",
      "MAE: 0.5469\n",
      "RMSE: 0.7602\n",
      "AUC score: 0.6720\n",
      "AP score: 0.5802\n",
      "Recall at top-K: 0.4301\n",
      "AUC score: 0.6042\n",
      "AP score: 0.5459\n",
      "Recall at top-K: 0.4223\n",
      "375 of 376\n",
      "all\n",
      "----------\n",
      "filtered: 0\n",
      "filtered: 1\n",
      "Pearson: 0.0497\n",
      "Spearman: 0.0504\n",
      "MAE: 0.7030\n",
      "RMSE: 0.8937\n",
      "AUC score: 0.6729\n",
      "AP score: 0.5856\n",
      "Recall at top-K: 0.4664\n",
      "AUC score: 0.6635\n",
      "AP score: 0.6082\n",
      "Recall at top-K: 0.4978\n"
     ]
    }
   ],
   "source": [
    "eval_plausibility_all_lps(\n",
    "    teacher, \n",
    "    teacher_params, \n",
    "    best_head_teacher_explainer, \n",
    "    best_head_teacher_explainer_params,\n",
    "    split='dev'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7defb4d7",
   "metadata": {},
   "source": [
    "### last layer attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "0179a39c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeviceArray([0.07685792, 0.07677209, 0.0766765 , 0.07660621, 0.07668299,\n",
       "             0.0766904 , 0.07666271, 0.07671636, 0.07712432, 0.07718218,\n",
       "             0.07728937, 0.07735462, 0.07738439], dtype=float32)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flax.linen.softmax(teacher_params['params']['scalarmix']['coeffs'])  # first item is the embedding layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d0fea930",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeviceArray(12, dtype=int32)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flax.linen.softmax(teacher_params['params']['scalarmix']['coeffs']).argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "91fd0c7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63 of 63\n",
      "en-de\n",
      "----------\n",
      "filtered: 0\n",
      "filtered: 0\n",
      "Pearson: 0.4250\n",
      "Spearman: 0.4282\n",
      "MAE: 0.5056\n",
      "RMSE: 0.6900\n",
      "AUC score: 0.5082\n",
      "AP score: 0.3179\n",
      "Recall at top-K: 0.1803\n",
      "AUC score: 0.4891\n",
      "AP score: 0.3287\n",
      "Recall at top-K: 0.1978\n",
      "63 of 63\n",
      "en-zh\n",
      "----------\n",
      "filtered: 0\n",
      "filtered: 0\n",
      "Pearson: 0.4491\n",
      "Spearman: 0.4538\n",
      "MAE: 0.5167\n",
      "RMSE: 0.6402\n",
      "AUC score: 0.6086\n",
      "AP score: 0.4767\n",
      "Recall at top-K: 0.3456\n",
      "AUC score: 0.4945\n",
      "AP score: 0.4421\n",
      "Recall at top-K: 0.3293\n",
      "63 of 63\n",
      "et-en\n",
      "----------\n",
      "filtered: 0\n",
      "filtered: 0\n",
      "Pearson: 0.6332\n",
      "Spearman: 0.6368\n",
      "MAE: 0.5586\n",
      "RMSE: 0.6877\n",
      "AUC score: 0.5070\n",
      "AP score: 0.4023\n",
      "Recall at top-K: 0.2681\n",
      "AUC score: 0.5028\n",
      "AP score: 0.3712\n",
      "Recall at top-K: 0.2703\n",
      "63 of 63\n",
      "ne-en\n",
      "----------\n",
      "filtered: 0\n",
      "filtered: 0\n",
      "Pearson: 0.6564\n",
      "Spearman: 0.6537\n",
      "MAE: 0.5005\n",
      "RMSE: 0.6361\n",
      "AUC score: 0.5478\n",
      "AP score: 0.6808\n",
      "Recall at top-K: 0.5897\n",
      "AUC score: 0.4768\n",
      "AP score: 0.6785\n",
      "Recall at top-K: 0.6477\n",
      "63 of 63\n",
      "ro-en\n",
      "----------\n",
      "filtered: 0\n",
      "filtered: 0\n",
      "Pearson: 0.7941\n",
      "Spearman: 0.7420\n",
      "MAE: 0.5030\n",
      "RMSE: 0.6408\n",
      "AUC score: 0.5226\n",
      "AP score: 0.4085\n",
      "Recall at top-K: 0.2922\n",
      "AUC score: 0.5655\n",
      "AP score: 0.3928\n",
      "Recall at top-K: 0.2652\n",
      "63 of 63\n",
      "ru-en\n",
      "----------\n",
      "filtered: 0\n",
      "filtered: 1\n",
      "Pearson: 0.6019\n",
      "Spearman: 0.5525\n",
      "MAE: 0.5469\n",
      "RMSE: 0.7602\n",
      "AUC score: 0.5574\n",
      "AP score: 0.5060\n",
      "Recall at top-K: 0.3607\n",
      "AUC score: 0.4954\n",
      "AP score: 0.4564\n",
      "Recall at top-K: 0.3360\n",
      "375 of 376\n",
      "all\n",
      "----------\n",
      "filtered: 0\n",
      "filtered: 1\n",
      "Pearson: 0.0497\n",
      "Spearman: 0.0504\n",
      "MAE: 0.7030\n",
      "RMSE: 0.8937\n",
      "AUC score: 0.5411\n",
      "AP score: 0.4771\n",
      "Recall at top-K: 0.3542\n",
      "AUC score: 0.5020\n",
      "AP score: 0.4577\n",
      "Recall at top-K: 0.3600\n"
     ]
    }
   ],
   "source": [
    "best_layer_teacher_explainer_params={\n",
    "    'normalize_head_coeffs': 'sparsemax',\n",
    "    'normalizer_fn': 'softmax',\n",
    "    'aggregator_idx': 'mean',\n",
    "    'aggregator_dim': 'row',\n",
    "    'init_fn': 'uniform',\n",
    "    'layer_idx': 11,  #9, None\n",
    "    'head_idx': None,  #5, None\n",
    "}\n",
    "best_layer_teacher_explainer, best_layer_teacher_explainer_params = create_explainer(\n",
    "    key=next(keyseq), \n",
    "    inputs=dummy_inputs, \n",
    "    state=dummy_state, \n",
    "    explainer_type='attention_explainer', \n",
    "    explainer_args=best_layer_teacher_explainer_params\n",
    ")\n",
    "eval_plausibility_all_lps(\n",
    "    teacher, \n",
    "    teacher_params, \n",
    "    best_layer_teacher_explainer, \n",
    "    best_layer_teacher_explainer_params,\n",
    "    split='dev'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae36857a",
   "metadata": {},
   "source": [
    "## Plotting the distribution of predictions and AUC scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f1cf53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define options for seaborn\n",
    "custom_params = {\n",
    "    'axes.spines.right': False,\n",
    "    'axes.spines.top': False,\n",
    "    'grid.color': '.85',\n",
    "    'grid.linestyle': ':'\n",
    "}\n",
    "_ = sns.set_theme(style='whitegrid', rc=custom_params),\n",
    "\n",
    "def plot_da_vs_expl_metric(metric_fn, das, e_golds, e_preds):\n",
    "    x = []\n",
    "    y = []\n",
    "    for da, gold, pred in zip(das, e_golds, e_preds):\n",
    "        if sum(gold) == 0 or sum(gold) == len(gold):\n",
    "            continue\n",
    "        y.append(metric_fn(gold, pred))\n",
    "        x.append(da)\n",
    "    x = np.array(x)\n",
    "    y = np.array(y)\n",
    "    fig, axs = plt.subplots(1, 3, figsize=(16, 4))\n",
    "    sns.histplot(x=x, y=y, ax=axs[0])\n",
    "    axs[0].set_xlabel('da')\n",
    "    axs[0].set_ylabel(str(metric_fn).split()[1])\n",
    "    sns.histplot(x, bins=20, ax=axs[1])\n",
    "    axs[1].set_xlabel('da')\n",
    "    sns.histplot(y, bins=20, ax=axs[2])\n",
    "    axs[2].set_xlabel(str(metric_fn).split()[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a0b03c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot predicted DA vs AUC for src and mt\n",
    "plot_da_vs_expl_metric(roc_auc_score, pred_scores, gold_expls_src, pred_expls_src)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e42f92e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_da_vs_expl_metric(roc_auc_score, pred_scores, gold_expls_mt, pred_expls_mt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e659af49",
   "metadata": {},
   "source": [
    "## Check results for all layers (slooow -> very inefficient)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "347adcb6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for layer_id in range(12):\n",
    "    valid_tokens, valid_masks, valid_explanations, valid_outputs = get_explanations(\n",
    "        valid_data, strategy='layer_average', layer_id=layer_id\n",
    "    )\n",
    "    src_expls, mt_expls, src_pieces, mt_pieces = get_src_and_mt_explanations(\n",
    "        valid_tokens, valid_masks, valid_explanations, reduction='sum'\n",
    "    )\n",
    "    print('LAYER: {}'.format(layer_id))\n",
    "    _ = evaluate_word_level(gold_expls_src, src_expls)\n",
    "    _ = evaluate_word_level(gold_expls_mt, mt_expls)\n",
    "    print('---')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23aa5101",
   "metadata": {},
   "source": [
    "## Check results for all heads in all layers ((very slow)^2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37f9e36b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for layer_id in range(12):\n",
    "    for head_id in range(12):\n",
    "        valid_tokens, valid_masks, valid_explanations, valid_outputs = get_explanations(\n",
    "            valid_data, strategy='layer_head', layer_id=layer_id, head_id=head_id\n",
    "        )\n",
    "        src_expls, mt_expls, src_pieces, mt_pieces = get_src_and_mt_explanations(\n",
    "            valid_tokens, valid_masks, valid_explanations, reduction='sum'\n",
    "        )\n",
    "        print('LAYER: {} | HEAD: {}'.format(layer_id, head_id))\n",
    "        _ = evaluate_word_level(gold_expls_src, src_expls)\n",
    "        _ = evaluate_word_level(gold_expls_mt, mt_expls)\n",
    "        print('---')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
