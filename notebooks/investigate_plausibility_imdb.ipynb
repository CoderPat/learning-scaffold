{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0f173f6e",
   "metadata": {},
   "source": [
    "set cuda id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5442597",
   "metadata": {},
   "outputs": [],
   "source": [
    "%env CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
    "%env CUDA_VISIBLE_DEVICES=4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0343ff12",
   "metadata": {},
   "source": [
    "Install dependencies for computing metrics and plots:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b7502e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip3 install numpy scipy pandas seaborn matplotlib sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6e1ab61",
   "metadata": {},
   "source": [
    "## Basic imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "111e491d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import flax\n",
    "from entmax_jax import sparsemax\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from IPython.display import display, HTML\n",
    "from functools import partial\n",
    "import json\n",
    "from entmax_jax.activations import sparsemax, entmax15\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "\n",
    "from meta_expl.explainers import load_explainer\n",
    "from meta_expl.models import load_model\n",
    "from meta_expl.data.imdb import load_data, dataloader\n",
    "from meta_expl.data.movies_rationales import dataloader as movie_dataloader\n",
    "from meta_expl.data.movies_rationales import load_data as movie_load_data\n",
    "\n",
    "from evaluate_explanations import evaluate_word_level, evaluate_sentence_level, aggregate_pieces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "696c7a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data utils\n",
    "def unroll(list_of_lists):\n",
    "    return [e for ell in list_of_lists for e in ell]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0051472",
   "metadata": {},
   "source": [
    "## Define args and load stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e77dafcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# arguments\n",
    "arch = \"google/electra-small-discriminator\"\n",
    "num_classes = 2\n",
    "task_type = \"classification\"\n",
    "max_len = 256\n",
    "batch_size = 32\n",
    "seed = 1\n",
    "setup = \"static_teacher\"\n",
    "\n",
    "teacher_dir = 'data/imdb-electra-models/teacher_dir'\n",
    "explainer_dir = 'data/imdb-electra-models/teacher_expl_dir'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a323ee16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dummy inputs for model instantiation\n",
    "input_ids = jnp.ones((batch_size, max_len), jnp.int32)\n",
    "dummy_inputs = {\n",
    "    \"input_ids\": input_ids,\n",
    "    \"attention_mask\": jnp.ones_like(input_ids),\n",
    "    \"token_type_ids\": jnp.arange(jnp.atleast_2d(input_ids).shape[-1]),\n",
    "    \"position_ids\": jnp.ones_like(input_ids),\n",
    "}\n",
    "dummy_inputs['input_ids'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1f4f9ad",
   "metadata": {},
   "source": [
    "### load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c07f5c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "test_data = movie_load_data(setup, \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c35cadf",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f90ea756",
   "metadata": {},
   "source": [
    "### load tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbf471df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import ElectraTokenizerFast\n",
    "tokenizer = ElectraTokenizerFast.from_pretrained(arch)\n",
    "vocab_size = len(tokenizer)\n",
    "cls_id = tokenizer.cls_token_id\n",
    "sep_id = tokenizer.sep_token_id\n",
    "pad_id = tokenizer.pad_token_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7df6d85",
   "metadata": {},
   "source": [
    "### load model and explainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "478ee21f",
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher, teacher_params, dummy_state = load_model(teacher_dir, dummy_inputs, batch_size, max_len)\n",
    "teacher_explainer, teacher_explainer_params = load_explainer(explainer_dir, dummy_inputs, state=dummy_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f482d52e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from meta_expl.utils import PRNGSequence\n",
    "from meta_expl.explainers import create_explainer\n",
    "keyseq = PRNGSequence(11)\n",
    "teacher_explainer_params_non_trained={\n",
    "    'normalize_head_coeffs': 'sparsemax',\n",
    "    'normalizer_fn': 'softmax',\n",
    "    'aggregator_idx': 'mean',\n",
    "    'aggregator_dim': 'row',\n",
    "    'init_fn': 'uniform',\n",
    "    'layer_idx': None,\n",
    "    'head_idx': None\n",
    "}\n",
    "teacher_explainer_non_trained, teacher_explainer_params_non_trained = create_explainer(\n",
    "    key=next(keyseq),\n",
    "    inputs=dummy_inputs,\n",
    "    state=dummy_state,\n",
    "    explainer_type='attention_explainer',\n",
    "    explainer_args=teacher_explainer_params_non_trained,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe63b22a",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_head_teacher_explainer_params={\n",
    "    'normalize_head_coeffs': 'sparsemax',\n",
    "    'normalizer_fn': 'softmax',\n",
    "    'aggregator_idx': 'mean',\n",
    "    'aggregator_dim': 'row',\n",
    "    'init_fn': 'uniform',\n",
    "    'layer_idx': 9,  #9, None\n",
    "    'head_idx': 5,  #5, None\n",
    "}\n",
    "best_head_teacher_explainer, best_head_teacher_explainer_params = create_explainer(\n",
    "    key=next(keyseq), \n",
    "    inputs=dummy_inputs, \n",
    "    state=dummy_state, \n",
    "    explainer_type='attention_explainer', \n",
    "    explainer_args=best_head_teacher_explainer_params\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f07e2ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_layer_teacher_explainer_params={\n",
    "    'normalize_head_coeffs': 'sparsemax',\n",
    "    'normalizer_fn': 'softmax',\n",
    "    'aggregator_idx': 'mean',\n",
    "    'aggregator_dim': 'row',\n",
    "    'init_fn': 'uniform',\n",
    "    'layer_idx': 10,  #9, None\n",
    "    'head_idx': None,  #5, None\n",
    "}\n",
    "best_layer_teacher_explainer, best_layer_teacher_explainer_params = create_explainer(\n",
    "    key=next(keyseq), \n",
    "    inputs=dummy_inputs, \n",
    "    state=dummy_state, \n",
    "    explainer_type='attention_explainer', \n",
    "    explainer_args=best_layer_teacher_explainer_params\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7ac6a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_gradient_teacher_explainer, input_gradient_teacher_explainer_params = create_explainer(\n",
    "    key=next(keyseq), \n",
    "    inputs=dummy_inputs, \n",
    "    state=dummy_state, \n",
    "    explainer_type='gradient_input_explainer', \n",
    "    model_extras={\n",
    "        \"grad_fn\": teacher.apply(\n",
    "            teacher_params, dummy_inputs, method=teacher.embeddings_grad_fn\n",
    "        )\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbbf34ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "int_gradient_teacher_explainer, int_gradient_teacher_explainer_params = create_explainer(\n",
    "    key=next(keyseq), \n",
    "    inputs=dummy_inputs, \n",
    "    state=dummy_state, \n",
    "    explainer_type='integrated_gradients_explainer', \n",
    "    model_extras={\n",
    "        \"grad_fn\": teacher.apply(\n",
    "            teacher_params, dummy_inputs, method=teacher.embeddings_grad_fn\n",
    "        )\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2d09885",
   "metadata": {},
   "source": [
    "### look at the coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e0f46b",
   "metadata": {},
   "outputs": [],
   "source": [
    "hc = sparsemax(teacher_explainer_params['params']['head_coeffs']).reshape(12, 4)\n",
    "hc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a706e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for a, b in zip(*hc.nonzero()):\n",
    "    print(a+1, b+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18549d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the layers with the highest coefficients\n",
    "layer_coeffs = hc.mean(-1).tolist()\n",
    "sorted(list(zip(list(range(1, len(layer_coeffs)+1)), layer_coeffs)), key=lambda k: k[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4048be98",
   "metadata": {},
   "outputs": [],
   "source": [
    "coeffs = np.asarray(hc)\n",
    "fig, ax = plt.subplots(figsize=(4, 4))\n",
    "ax.imshow(coeffs, cmap='Greens')\n",
    "ax.set_xticks(list(range(12)))\n",
    "ax.set_yticks(list(range(12)))\n",
    "ax.set_xlabel('Head')\n",
    "ax.set_ylabel('Layer')\n",
    "ax.set_title('Head coefficients')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0a705b0",
   "metadata": {},
   "source": [
    "## Get explanations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33bd87c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_expls(data, t, t_p, t_e, t_e_p, s=None, s_p=None, s_e=None, s_e_p=None, is_grad_based=False):\n",
    "    all_tokens = []\n",
    "    all_masks = []\n",
    "    all_explanations = []\n",
    "    all_outputs = []\n",
    "    for i, (x, y) in enumerate(movie_dataloader(data, tokenizer, batch_size=batch_size, max_len=max_len, shuffle=False)):\n",
    "        print('{} of {}'.format(i, len(data)//batch_size), end='\\r')\n",
    "        y_teacher, teacher_attn = t.apply(t_p, **x, deterministic=True)\n",
    "        y_teacher = jnp.argmax(y_teacher, axis=-1) if task_type == \"classification\" else y_teacher\n",
    "        if is_grad_based:\n",
    "            teacher_extras = {\n",
    "                \"grad_fn\": t.apply(t_p, x, method=t.embeddings_grad_fn)\n",
    "            }\n",
    "            teacher_expl, _ = t_e.apply(t_e_p, x, teacher_attn, **teacher_extras)\n",
    "        else:\n",
    "            teacher_expl, _ = t_e.apply(t_e_p, x, teacher_attn)\n",
    "        # teacher_rep = teacher_attn['hidden_states'][0][0]\n",
    "        # teacher_attn = np.asarray(jnp.stack(teacher_attn['attentions']).transpose([1, 0, 2, 3, 4]))\n",
    "        \n",
    "        if s is not None:\n",
    "            y_student, student_attn = s.apply(s_p, **x)\n",
    "            y_student = jnp.argmax(y_student, axis=-1) if task_type == \"classification\" else y_student\n",
    "            student_expl, _ = student_explainer.apply(s_e_p, x, student_attn)\n",
    "            # student_attn = np.asarray(jnp.stack(student_attn['attentions']).transpose([1, 0, 2, 3, 4]))\n",
    "        \n",
    "        # convert everything to lists\n",
    "        batch_ids = x['input_ids'].tolist()\n",
    "        batch_tokens = [tokenizer.convert_ids_to_tokens(ids) for ids in batch_ids]\n",
    "        batch_masks = [[not tk.startswith('##') for tk in tokens] for tokens in batch_tokens]\n",
    "        batch_expls = teacher_expl.tolist()\n",
    "        \n",
    "        # filter out pad\n",
    "        batch_valid_len = x['attention_mask'].sum(-1).tolist()\n",
    "        batch_z = []\n",
    "        for i in range(len(batch_valid_len)):\n",
    "            n = batch_valid_len[i]\n",
    "            batch_ids[i] = batch_ids[i][:n]\n",
    "            batch_tokens[i] = batch_tokens[i][:n]\n",
    "            batch_masks[i] = batch_masks[i][:n]\n",
    "            batch_expls[i] = batch_expls[i][:n]\n",
    "        \n",
    "        all_tokens.extend(batch_tokens)\n",
    "        all_masks.extend(batch_masks)\n",
    "        all_explanations.extend(batch_expls)\n",
    "        all_outputs.extend(y_teacher.tolist())\n",
    "        \n",
    "    return all_tokens, all_masks, all_explanations, all_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeea2602",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_ok = 0\n",
    "total_er = 0\n",
    "\n",
    "def find_index_sublist(v, u_pad):\n",
    "    global total_ok, total_er\n",
    "    m = u_pad.index(102)\n",
    "    u = u_pad[1:m]\n",
    "    n = len(u)\n",
    "    for i in range(len(v)-n):\n",
    "        if v[i:i+n] == u:\n",
    "            total_ok += 1\n",
    "            return i, i+n\n",
    "    total_er += 1\n",
    "    return None, None\n",
    "\n",
    "def convert_evidences_to_mask(x, e):\n",
    "    start_end_idxs = [find_index_sublist(x, e_) for e_ in e]\n",
    "    mask = [0] * len(x)\n",
    "    for a, b in start_end_idxs:\n",
    "        if a is not None and b is not None:\n",
    "            for j in range(a, b):\n",
    "                mask[j] = 1\n",
    "    return mask\n",
    "\n",
    "all_gold_explanations = []\n",
    "for i, sample in enumerate(test_data):\n",
    "    if len(sample['evidences']) == 0:\n",
    "        sample['evidences'] = ['justarandomwordhere']\n",
    "    sample['review'] = sample['review'].replace('\\n', ' ')\n",
    "    x = tokenizer(\n",
    "        sample['review'],\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        return_tensors=\"jax\",\n",
    "        max_length=max_len,\n",
    "    )\n",
    "    e = tokenizer(\n",
    "        sample['evidences'],\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        return_tensors=\"jax\",\n",
    "        max_length=max_len,\n",
    "    )\n",
    "    # z = convert_evidences_to_mask(sample['review'], sample['evidences'])\n",
    "    z = convert_evidences_to_mask(x['input_ids'][0].tolist(), e['input_ids'].tolist())\n",
    "    n = x['attention_mask'].sum(-1).tolist()[0]\n",
    "    z = z[:n]\n",
    "    all_gold_explanations.append(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd0148f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_ok, total_er, total_ok / (total_ok+total_er)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ead4a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_tokens, valid_masks, valid_explanations, valid_outputs = get_expls(\n",
    "    test_data, teacher, teacher_params, teacher_explainer, teacher_explainer_params \n",
    ")\n",
    "list(map(len, [valid_tokens, valid_masks, valid_explanations, valid_outputs]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2ab6508",
   "metadata": {},
   "source": [
    "### Aggregate scores for word pieces in SRC and MT independently"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31a1ae7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from utils import aggregate_pieces\n",
    "\n",
    "def get_piece_explanations(all_tokens, all_fp_masks, all_explanations, reduction):\n",
    "    all_pieces = []\n",
    "    for tokens, expl, fp_mask in zip(all_tokens, all_explanations, all_fp_masks):\n",
    "        # aggregate word pieces scores (use my old good torch function)\n",
    "        agg_expl = aggregate_pieces(torch.tensor(expl), torch.tensor(fp_mask), reduction)\n",
    "        # remove <s> and </s>\n",
    "        agg_expl = agg_expl.tolist()[1:-1]\n",
    "        all_pieces.append(agg_expl)\n",
    "    return all_pieces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea29155a",
   "metadata": {},
   "outputs": [],
   "source": [
    "reduction = 'sum'  # first, sum, mean, max\n",
    "valid_masks = [[not tk.startswith('##') for tk in tokens] for tokens in valid_tokens]\n",
    "all_expls = get_piece_explanations(\n",
    "    valid_tokens, valid_masks, valid_explanations, reduction=reduction\n",
    ")\n",
    "all_gold_expls = get_piece_explanations(\n",
    "    valid_tokens, valid_masks, all_gold_explanations, reduction='max'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99616e11",
   "metadata": {},
   "source": [
    "## Evaluating explanations by comparing explanations with word-level QE tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e24974e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(map(sum, all_gold_expls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "874d3715",
   "metadata": {},
   "outputs": [],
   "source": [
    "gold_scores = [inp['label'] for inp in test_data]\n",
    "gold_expls = all_gold_expls\n",
    "pred_scores = valid_outputs\n",
    "pred_expls = all_expls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0a6069c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Acc:', np.mean(np.array(gold_scores) == np.array(pred_scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fad2aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = evaluate_word_level(gold_expls, pred_expls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14afc36c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_plausibility(data, t, t_p, t_e, t_e_p, is_grad_based=False):\n",
    "    valid_tokens, valid_masks, valid_explanations, valid_outputs = get_expls(\n",
    "        data, t, t_p, t_e, t_e_p, is_grad_based=is_grad_based\n",
    "    )\n",
    "    pred_expls = get_piece_explanations(\n",
    "        valid_tokens, valid_masks, valid_explanations, reduction='sum'\n",
    "    )\n",
    "    gold_scores = [inp['label'] for inp in data]\n",
    "    gold_expls = all_gold_expls\n",
    "    pred_scores = valid_outputs\n",
    "    print('Acc:', np.mean(np.array(gold_scores) == np.array(pred_scores)))\n",
    "    evaluate_word_level(gold_expls, pred_expls)\n",
    "    return pred_expls\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37d8adb4",
   "metadata": {},
   "source": [
    "### meta-learned explainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b2dcda8",
   "metadata": {},
   "outputs": [],
   "source": [
    "expls_mtl = eval_plausibility(\n",
    "    test_data,\n",
    "    teacher, \n",
    "    teacher_params, \n",
    "    teacher_explainer, \n",
    "    teacher_explainer_params, \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41148ff6",
   "metadata": {},
   "source": [
    "### all attention layers and heads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a07e110",
   "metadata": {},
   "outputs": [],
   "source": [
    "expls_all_attn = eval_plausibility(\n",
    "    test_data,\n",
    "    teacher, \n",
    "    teacher_params, \n",
    "    teacher_explainer_non_trained, \n",
    "    teacher_explainer_params_non_trained,\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5115340",
   "metadata": {},
   "source": [
    "### gradient x input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f2af246",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_plausibility(\n",
    "    test_data,\n",
    "    teacher, \n",
    "    teacher_params, \n",
    "    input_gradient_teacher_explainer, \n",
    "    input_gradient_teacher_explainer_params,\n",
    "    is_grad_based=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "341c6001",
   "metadata": {},
   "source": [
    "### integrated gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d62e91ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_plausibility(\n",
    "    test_data,\n",
    "    teacher, \n",
    "    teacher_params, \n",
    "    int_gradient_teacher_explainer, \n",
    "    int_gradient_teacher_explainer_params,\n",
    "    is_grad_based=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2153c55",
   "metadata": {},
   "source": [
    "### best attention layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15514746",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_plausibility(\n",
    "    test_data,\n",
    "    teacher, \n",
    "    teacher_params, \n",
    "    best_layer_teacher_explainer, \n",
    "    best_layer_teacher_explainer_params,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6926720a",
   "metadata": {},
   "source": [
    "### best attention head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3734617c",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_plausibility(\n",
    "    test_data,\n",
    "    teacher, \n",
    "    teacher_params, \n",
    "    best_head_teacher_explainer, \n",
    "    best_head_teacher_explainer_params,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7defb4d7",
   "metadata": {},
   "source": [
    "### last layer attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0179a39c",
   "metadata": {},
   "outputs": [],
   "source": [
    "flax.linen.softmax(teacher_params['params']['scalarmix']['coeffs'])  # first item is the embedding layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0fea930",
   "metadata": {},
   "outputs": [],
   "source": [
    "flax.linen.softmax(teacher_params['params']['scalarmix']['coeffs']).argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91fd0c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_layer_teacher_explainer_params={\n",
    "    'normalize_head_coeffs': 'sparsemax',\n",
    "    'normalizer_fn': 'softmax',\n",
    "    'aggregator_idx': 'mean',\n",
    "    'aggregator_dim': 'row',\n",
    "    'init_fn': 'uniform',\n",
    "    'layer_idx': 11,\n",
    "    'head_idx': None,\n",
    "}\n",
    "best_layer_teacher_explainer, best_layer_teacher_explainer_params = create_explainer(\n",
    "    key=next(keyseq), \n",
    "    inputs=dummy_inputs, \n",
    "    state=dummy_state, \n",
    "    explainer_type='attention_explainer', \n",
    "    explainer_args=best_layer_teacher_explainer_params\n",
    ")\n",
    "eval_plausibility(\n",
    "    test_data,\n",
    "    teacher, \n",
    "    teacher_params, \n",
    "    best_layer_teacher_explainer, \n",
    "    best_layer_teacher_explainer_params,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9e32574",
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher.num_encoder_layers, teacher.num_heads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a13564cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer_id in range(12):\n",
    "    print('-------------')\n",
    "    print('layer:', layer_id)\n",
    "    best_layer_teacher_explainer_params={\n",
    "        'normalize_head_coeffs': 'sparsemax',\n",
    "        'normalizer_fn': 'softmax',\n",
    "        'aggregator_idx': 'mean',\n",
    "        'aggregator_dim': 'row',\n",
    "        'init_fn': 'uniform',\n",
    "        'layer_idx': layer_id,\n",
    "        'head_idx': None,\n",
    "    }\n",
    "    best_layer_teacher_explainer, best_layer_teacher_explainer_params = create_explainer(\n",
    "        key=next(keyseq), \n",
    "        inputs=dummy_inputs, \n",
    "        state=dummy_state, \n",
    "        explainer_type='attention_explainer', \n",
    "        explainer_args=best_layer_teacher_explainer_params\n",
    "    )\n",
    "    eval_plausibility(\n",
    "        test_data,\n",
    "        teacher, \n",
    "        teacher_params, \n",
    "        best_layer_teacher_explainer, \n",
    "        best_layer_teacher_explainer_params,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ba3c580",
   "metadata": {},
   "outputs": [],
   "source": [
    "jax.random.bernoulli(next(keyseq), p=0.5, shape=(10,)).astype(int).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a40f32f",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_1 = sum(map(sum, gold_expls))\n",
    "t_n = sum(map(len, gold_expls))\n",
    "\n",
    "print(t_1/t_n)\n",
    "\n",
    "fake_pred_expls = [\n",
    "    [1]*len(ge) for ge in gold_expls \n",
    "]\n",
    "_ = evaluate_word_level(gold_expls, fake_pred_expls)\n",
    "\n",
    "fake_pred_expls2 = [\n",
    "    jax.random.bernoulli(next(keyseq), p=t_1/t_n, shape=(len(ge),)).astype(int).tolist() for ge in gold_expls \n",
    "]\n",
    "_ = evaluate_word_level(gold_expls, fake_pred_expls2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d25af46",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer_id in range(12):\n",
    "    for head_id in range(4):\n",
    "        print('---------------------')\n",
    "        print('layer {} | head {}'.format(layer_id, head_id))\n",
    "        best_layer_teacher_explainer_params={\n",
    "            'normalize_head_coeffs': 'sparsemax',\n",
    "            'normalizer_fn': 'softmax',\n",
    "            'aggregator_idx': 'mean',\n",
    "            'aggregator_dim': 'row',\n",
    "            'init_fn': 'uniform',\n",
    "            'layer_idx': layer_id,\n",
    "            'head_idx': head_id,\n",
    "        }\n",
    "        best_layer_teacher_explainer, best_layer_teacher_explainer_params = create_explainer(\n",
    "            key=next(keyseq), \n",
    "            inputs=dummy_inputs, \n",
    "            state=dummy_state, \n",
    "            explainer_type='attention_explainer', \n",
    "            explainer_args=best_layer_teacher_explainer_params\n",
    "        )\n",
    "        eval_plausibility(\n",
    "            test_data,\n",
    "            teacher, \n",
    "            teacher_params, \n",
    "            best_layer_teacher_explainer, \n",
    "            best_layer_teacher_explainer_params,\n",
    "        )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
