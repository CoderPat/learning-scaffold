{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0f173f6e",
   "metadata": {},
   "source": [
    "set cuda id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e5442597",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
      "env: CUDA_VISIBLE_DEVICES=3\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
    "%env CUDA_VISIBLE_DEVICES=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "111e491d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import flax\n",
    "from entmax_jax import sparsemax\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from IPython.display import display, HTML\n",
    "from functools import partial\n",
    "import json\n",
    "from entmax_jax.activations import sparsemax, entmax15\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "\n",
    "from meta_expl.explainers import load_explainer\n",
    "from meta_expl.models import load_model\n",
    "from meta_expl.data.mlqe import dataloader\n",
    "\n",
    "from evaluate_explanations import evaluate_word_level, evaluate_sentence_level, aggregate_pieces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7cc32d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from argparse import Namespace\n",
    "args = Namespace(\n",
    "    seed=0,\n",
    "    setup='static_teacher',  # \"no_teacher\", \"static_teacher\", \"learnable_teacher\"\n",
    "    task='mlqe',\n",
    "    task_params={\n",
    "        'eval_lp': 'ro-en',\n",
    "    },\n",
    "    arch='xlm-r',\n",
    "    tokenizer='xlm-r',\n",
    "    \n",
    "    explainer='attention_explainer',\n",
    "    explainer_params={\n",
    "        'normalize_head_coeffs': 'sparsemax',\n",
    "        'normalizer_fn': 'softmax',\n",
    "        'aggregator_idx': 'mean',\n",
    "        'aggregator_dim': 'row',\n",
    "        'layer_idx': -1,\n",
    "        'head_idx': None\n",
    "    },\n",
    "    teacher_explainer='attention_explainer',\n",
    "    teacher_explainer_params={\n",
    "        'normalize_head_coeffs': 'sparsemax',\n",
    "        'normalizer_fn': 'softmax',\n",
    "        'aggregator_idx': 'mean',\n",
    "        'aggregator_dim': 'row',\n",
    "        'init_fn': 'uniform',\n",
    "        'layer_idx': 9,\n",
    "        'head_idx': 5,\n",
    "    },\n",
    "    initialize_embeddings=True,\n",
    "    num_examples=4100,\n",
    "    \n",
    "    max_len=256,\n",
    "    num_epochs=None,\n",
    "    kld_coeff=5,\n",
    "    patience=5,\n",
    "    optimizer='sgd',\n",
    "    learning_rate=1e-5,\n",
    "    warmup_steps=4000,\n",
    "    batch_size=16,\n",
    "    clip_grads=1.0,\n",
    "    weight_decay=0.01,\n",
    "    \n",
    "    # meta-learning\n",
    "    meta_interval=1,\n",
    "    meta_warmup=0,\n",
    "    metaoptimizer='adamw',\n",
    "    meta_lr=1e-3,\n",
    "    meta_explicit=False,\n",
    "    num_resets=0,\n",
    "    \n",
    "    teacher_dir='data/mlqe-xlmr-explainer/teacher_dir',\n",
    "    model_dir=None,\n",
    "    explainer_dir=None,\n",
    "    teacher_explainer_dir=None,\n",
    "    \n",
    "    wandb=None,\n",
    "    log_teacher_params=None,\n",
    "    save_test_outputs=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a323ee16",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:Unable to initialize backend 'tpu_driver': NOT_FOUND: Unable to find driver in registry given worker: \n",
      "INFO:absl:Unable to initialize backend 'tpu': INVALID_ARGUMENT: TpuPlatform is not available.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(16, 256)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create dummy inputs for model instantiation\n",
    "input_ids = jnp.ones((args.batch_size, args.max_len), jnp.int32)\n",
    "dummy_inputs = {\n",
    "    \"input_ids\": input_ids,\n",
    "    \"attention_mask\": jnp.ones_like(input_ids),\n",
    "    \"token_type_ids\": jnp.arange(jnp.atleast_2d(input_ids).shape[-1]),\n",
    "    \"position_ids\": jnp.ones_like(input_ids),\n",
    "}\n",
    "dummy_inputs['input_ids'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fa2aa825",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a model of type xlm-roberta to instantiate a model of type roberta. This is not supported for all configurations of models and can yield errors.\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing FlaxRobertaForSequenceClassification: {('roberta', 'pooler', 'dense', 'kernel'), ('lm_head', 'dense', 'bias'), ('lm_head', 'layer_norm', 'kernel'), ('lm_head', 'bias'), ('lm_head', 'dense', 'kernel'), ('lm_head', 'layer_norm', 'bias'), ('roberta', 'pooler', 'dense', 'bias'), ('lm_head', 'decoder', 'kernel')}\n",
      "- This IS expected if you are initializing FlaxRobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing FlaxRobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of FlaxRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: {('classifier', 'dense', 'kernel'), ('classifier', 'out_proj', 'bias'), ('classifier', 'dense', 'bias'), ('classifier', 'out_proj', 'kernel')}\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "INFO:absl:An exponential schedule was set with a non-positive `transition_steps` value; this will result in a constant schedule with value `init_value`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/-1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-21 13:26:37.598818: W external/org_tensorflow/tensorflow/core/common_runtime/bfc_allocator.cc:479] Allocator (GPU_0_bfc) ran out of memory trying to allocate 3.50GiB (rounded to 3755229440)requested by op \n",
      "2022-02-21 13:26:37.601067: W external/org_tensorflow/tensorflow/core/common_runtime/bfc_allocator.cc:491] *__******************_***********************_________________*****_________________________________\n",
      "2022-02-21 13:26:37.608288: E external/org_tensorflow/tensorflow/compiler/xla/pjrt/pjrt_stream_executor_client.cc:2124] Execution of replica 0 failed: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 3755229344 bytes.\n",
      "BufferAssignment OOM Debugging.\n",
      "BufferAssignment stats:\n",
      "             parameter allocation:    2.07GiB\n",
      "              constant allocation:       112B\n",
      "        maybe_live_out allocation:    1.04GiB\n",
      "     preallocated temp allocation:    3.50GiB\n",
      "  preallocated temp fragmentation:   35.92MiB (1.00%)\n",
      "                 total allocation:    6.60GiB\n",
      "              total fragmentation:  969.68MiB (14.34%)\n",
      "Peak buffers:\n",
      "\tBuffer 1:\n",
      "\t\tSize: 732.43MiB\n",
      "\t\tEntry Parameter Subshape: f32[250002,768]\n",
      "\t\t==========================\n",
      "\n",
      "\tBuffer 2:\n",
      "\t\tSize: 732.43MiB\n",
      "\t\tEntry Parameter Subshape: f32[250002,768]\n",
      "\t\t==========================\n",
      "\n",
      "\tBuffer 3:\n",
      "\t\tSize: 732.43MiB\n",
      "\t\tOperator: op_name=\"jit(train_step_with_teacher)/jit(main)/add\" source_file=\"/home/mtreviso/meta-expl/env/lib/python3.8/site-packages/optax/_src/update.py\" source_line=43\n",
      "\t\tXLA Label: fusion\n",
      "\t\tShape: f32[250002,768]\n",
      "\t\t==========================\n",
      "\n",
      "\tBuffer 4:\n",
      "\t\tSize: 48.00MiB\n",
      "\t\tXLA Label: custom-call\n",
      "\t\tShape: f32[4096,3072]\n",
      "\t\t==========================\n",
      "\n",
      "\tBuffer 5:\n",
      "\t\tSize: 48.00MiB\n",
      "\t\tXLA Label: custom-call\n",
      "\t\tShape: f32[16,12,256,256]\n",
      "\t\t==========================\n",
      "\n",
      "\tBuffer 6:\n",
      "\t\tSize: 48.00MiB\n",
      "\t\tXLA Label: custom-call\n",
      "\t\tShape: f32[4096,3072]\n",
      "\t\t==========================\n",
      "\n",
      "\tBuffer 7:\n",
      "\t\tSize: 48.00MiB\n",
      "\t\tXLA Label: custom-call\n",
      "\t\tShape: f32[16,12,256,256]\n",
      "\t\t==========================\n",
      "\n",
      "\tBuffer 8:\n",
      "\t\tSize: 48.00MiB\n",
      "\t\tXLA Label: custom-call\n",
      "\t\tShape: f32[4096,3072]\n",
      "\t\t==========================\n",
      "\n",
      "\tBuffer 9:\n",
      "\t\tSize: 48.00MiB\n",
      "\t\tXLA Label: custom-call\n",
      "\t\tShape: f32[16,12,256,256]\n",
      "\t\t==========================\n",
      "\n",
      "\tBuffer 10:\n",
      "\t\tSize: 48.00MiB\n",
      "\t\tXLA Label: custom-call\n",
      "\t\tShape: f32[4096,3072]\n",
      "\t\t==========================\n",
      "\n",
      "\tBuffer 11:\n",
      "\t\tSize: 48.00MiB\n",
      "\t\tXLA Label: custom-call\n",
      "\t\tShape: f32[16,12,256,256]\n",
      "\t\t==========================\n",
      "\n",
      "\tBuffer 12:\n",
      "\t\tSize: 48.00MiB\n",
      "\t\tXLA Label: custom-call\n",
      "\t\tShape: f32[4096,3072]\n",
      "\t\t==========================\n",
      "\n",
      "\tBuffer 13:\n",
      "\t\tSize: 48.00MiB\n",
      "\t\tXLA Label: custom-call\n",
      "\t\tShape: f32[16,12,256,256]\n",
      "\t\t==========================\n",
      "\n",
      "\tBuffer 14:\n",
      "\t\tSize: 48.00MiB\n",
      "\t\tXLA Label: custom-call\n",
      "\t\tShape: f32[4096,3072]\n",
      "\t\t==========================\n",
      "\n",
      "\tBuffer 15:\n",
      "\t\tSize: 48.00MiB\n",
      "\t\tXLA Label: custom-call\n",
      "\t\tShape: f32[16,12,256,256]\n",
      "\t\t==========================\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "RESOURCE_EXHAUSTED: Out of memory while trying to allocate 3755229344 bytes.\nBufferAssignment OOM Debugging.\nBufferAssignment stats:\n             parameter allocation:    2.07GiB\n              constant allocation:       112B\n        maybe_live_out allocation:    1.04GiB\n     preallocated temp allocation:    3.50GiB\n  preallocated temp fragmentation:   35.92MiB (1.00%)\n                 total allocation:    6.60GiB\n              total fragmentation:  969.68MiB (14.34%)\nPeak buffers:\n\tBuffer 1:\n\t\tSize: 732.43MiB\n\t\tEntry Parameter Subshape: f32[250002,768]\n\t\t==========================\n\n\tBuffer 2:\n\t\tSize: 732.43MiB\n\t\tEntry Parameter Subshape: f32[250002,768]\n\t\t==========================\n\n\tBuffer 3:\n\t\tSize: 732.43MiB\n\t\tOperator: op_name=\"jit(train_step_with_teacher)/jit(main)/add\" source_file=\"/home/mtreviso/meta-expl/env/lib/python3.8/site-packages/optax/_src/update.py\" source_line=43\n\t\tXLA Label: fusion\n\t\tShape: f32[250002,768]\n\t\t==========================\n\n\tBuffer 4:\n\t\tSize: 48.00MiB\n\t\tXLA Label: custom-call\n\t\tShape: f32[4096,3072]\n\t\t==========================\n\n\tBuffer 5:\n\t\tSize: 48.00MiB\n\t\tXLA Label: custom-call\n\t\tShape: f32[16,12,256,256]\n\t\t==========================\n\n\tBuffer 6:\n\t\tSize: 48.00MiB\n\t\tXLA Label: custom-call\n\t\tShape: f32[4096,3072]\n\t\t==========================\n\n\tBuffer 7:\n\t\tSize: 48.00MiB\n\t\tXLA Label: custom-call\n\t\tShape: f32[16,12,256,256]\n\t\t==========================\n\n\tBuffer 8:\n\t\tSize: 48.00MiB\n\t\tXLA Label: custom-call\n\t\tShape: f32[4096,3072]\n\t\t==========================\n\n\tBuffer 9:\n\t\tSize: 48.00MiB\n\t\tXLA Label: custom-call\n\t\tShape: f32[16,12,256,256]\n\t\t==========================\n\n\tBuffer 10:\n\t\tSize: 48.00MiB\n\t\tXLA Label: custom-call\n\t\tShape: f32[4096,3072]\n\t\t==========================\n\n\tBuffer 11:\n\t\tSize: 48.00MiB\n\t\tXLA Label: custom-call\n\t\tShape: f32[16,12,256,256]\n\t\t==========================\n\n\tBuffer 12:\n\t\tSize: 48.00MiB\n\t\tXLA Label: custom-call\n\t\tShape: f32[4096,3072]\n\t\t==========================\n\n\tBuffer 13:\n\t\tSize: 48.00MiB\n\t\tXLA Label: custom-call\n\t\tShape: f32[16,12,256,256]\n\t\t==========================\n\n\tBuffer 14:\n\t\tSize: 48.00MiB\n\t\tXLA Label: custom-call\n\t\tShape: f32[4096,3072]\n\t\t==========================\n\n\tBuffer 15:\n\t\tSize: 48.00MiB\n\t\tXLA Label: custom-call\n\t\tShape: f32[16,12,256,256]\n\t\t==========================\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [5]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmeta_expl\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtrain\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m main\n\u001b[0;32m----> 2\u001b[0m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/meta-expl/meta_expl/train.py:690\u001b[0m, in \u001b[0;36mmain\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m    683\u001b[0m     losses \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    684\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    685\u001b[0m     (\n\u001b[1;32m    686\u001b[0m         loss,\n\u001b[1;32m    687\u001b[0m         losses,\n\u001b[1;32m    688\u001b[0m         (params, explainer_params),\n\u001b[1;32m    689\u001b[0m         opt_state,\n\u001b[0;32m--> 690\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_step_with_teacher\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    691\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtask_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    692\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclassifier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    693\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexplainer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    694\u001b[0m \u001b[43m        \u001b[49m\u001b[43mteacher\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    695\u001b[0m \u001b[43m        \u001b[49m\u001b[43mteacher_explainer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    696\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    697\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    698\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    699\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexplainer_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    700\u001b[0m \u001b[43m        \u001b[49m\u001b[43mteacher_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    701\u001b[0m \u001b[43m        \u001b[49m\u001b[43mteacher_explainer_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    702\u001b[0m \u001b[43m        \u001b[49m\u001b[43mopt_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    703\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mkeyseq\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    704\u001b[0m \u001b[43m        \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    705\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    706\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkld_coeff\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    707\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    708\u001b[0m     \u001b[38;5;66;03m# print(explainer_params)\u001b[39;00m\n\u001b[1;32m    710\u001b[0m seen_samples \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m y\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n",
      "    \u001b[0;31m[... skipping hidden 6 frame]\u001b[0m\n",
      "File \u001b[0;32m~/meta-expl/env/lib/python3.8/site-packages/jax/_src/dispatch.py:444\u001b[0m, in \u001b[0;36m_execute_compiled\u001b[0;34m(name, compiled, output_buffer_counts, result_handlers, kept_var_idx, *args)\u001b[0m\n\u001b[1;32m    441\u001b[0m device, \u001b[38;5;241m=\u001b[39m compiled\u001b[38;5;241m.\u001b[39mlocal_devices()\n\u001b[1;32m    442\u001b[0m input_bufs \u001b[38;5;241m=\u001b[39m util\u001b[38;5;241m.\u001b[39mflatten(\n\u001b[1;32m    443\u001b[0m     device_put(x, device) \u001b[38;5;28;01mfor\u001b[39;00m i, x \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(args) \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m kept_var_idx)\n\u001b[0;32m--> 444\u001b[0m out_bufs \u001b[38;5;241m=\u001b[39m \u001b[43mcompiled\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_bufs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    445\u001b[0m check_special(name, out_bufs)\n\u001b[1;32m    446\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m output_buffer_counts \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mRuntimeError\u001b[0m: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 3755229344 bytes.\nBufferAssignment OOM Debugging.\nBufferAssignment stats:\n             parameter allocation:    2.07GiB\n              constant allocation:       112B\n        maybe_live_out allocation:    1.04GiB\n     preallocated temp allocation:    3.50GiB\n  preallocated temp fragmentation:   35.92MiB (1.00%)\n                 total allocation:    6.60GiB\n              total fragmentation:  969.68MiB (14.34%)\nPeak buffers:\n\tBuffer 1:\n\t\tSize: 732.43MiB\n\t\tEntry Parameter Subshape: f32[250002,768]\n\t\t==========================\n\n\tBuffer 2:\n\t\tSize: 732.43MiB\n\t\tEntry Parameter Subshape: f32[250002,768]\n\t\t==========================\n\n\tBuffer 3:\n\t\tSize: 732.43MiB\n\t\tOperator: op_name=\"jit(train_step_with_teacher)/jit(main)/add\" source_file=\"/home/mtreviso/meta-expl/env/lib/python3.8/site-packages/optax/_src/update.py\" source_line=43\n\t\tXLA Label: fusion\n\t\tShape: f32[250002,768]\n\t\t==========================\n\n\tBuffer 4:\n\t\tSize: 48.00MiB\n\t\tXLA Label: custom-call\n\t\tShape: f32[4096,3072]\n\t\t==========================\n\n\tBuffer 5:\n\t\tSize: 48.00MiB\n\t\tXLA Label: custom-call\n\t\tShape: f32[16,12,256,256]\n\t\t==========================\n\n\tBuffer 6:\n\t\tSize: 48.00MiB\n\t\tXLA Label: custom-call\n\t\tShape: f32[4096,3072]\n\t\t==========================\n\n\tBuffer 7:\n\t\tSize: 48.00MiB\n\t\tXLA Label: custom-call\n\t\tShape: f32[16,12,256,256]\n\t\t==========================\n\n\tBuffer 8:\n\t\tSize: 48.00MiB\n\t\tXLA Label: custom-call\n\t\tShape: f32[4096,3072]\n\t\t==========================\n\n\tBuffer 9:\n\t\tSize: 48.00MiB\n\t\tXLA Label: custom-call\n\t\tShape: f32[16,12,256,256]\n\t\t==========================\n\n\tBuffer 10:\n\t\tSize: 48.00MiB\n\t\tXLA Label: custom-call\n\t\tShape: f32[4096,3072]\n\t\t==========================\n\n\tBuffer 11:\n\t\tSize: 48.00MiB\n\t\tXLA Label: custom-call\n\t\tShape: f32[16,12,256,256]\n\t\t==========================\n\n\tBuffer 12:\n\t\tSize: 48.00MiB\n\t\tXLA Label: custom-call\n\t\tShape: f32[4096,3072]\n\t\t==========================\n\n\tBuffer 13:\n\t\tSize: 48.00MiB\n\t\tXLA Label: custom-call\n\t\tShape: f32[16,12,256,256]\n\t\t==========================\n\n\tBuffer 14:\n\t\tSize: 48.00MiB\n\t\tXLA Label: custom-call\n\t\tShape: f32[4096,3072]\n\t\t==========================\n\n\tBuffer 15:\n\t\tSize: 48.00MiB\n\t\tXLA Label: custom-call\n\t\tShape: f32[16,12,256,256]\n\t\t==========================\n\n"
     ]
    }
   ],
   "source": [
    "from meta_expl.train import main\n",
    "main(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a74f48e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
